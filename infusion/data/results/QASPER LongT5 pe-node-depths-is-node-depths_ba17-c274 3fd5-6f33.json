{
    "model_name": "LongT5",
    "task_name": "QASPER",
    "description": "pe-node-depths-is-node-depths_ba17-c274",
    "config": {
        "slurm_job_id": 152604,
        "description": "pe-node-depths-is-node-depths_ba17-c274",
        "remote_debug": false,
        "do_train": true,
        "use_dev_as_test_data": false,
        "load_model": true,
        "load_strict": false,
        "hash_to_load": "ba17-c274",
        "save_predictions": true,
        "max_input_length": 8192,
        "max_output_length": null,
        "max_depth": 20,
        "node_types": [
            "article-title",
            "abstract",
            "title",
            "p"
        ],
        "input_sequence": {
            "mode": "text_with_node_depths",
            "replace_newlines": false,
            "do_close": false,
            "node_separator": " ",
            "include_node_types": [
                "article-title",
                "abstract",
                "title",
                "p"
            ],
            "use_core_node_types_only": true,
            "use_bos_eos_token": false,
            "bos_token": null,
            "eos_token": null
        },
        "position_embeddings": {
            "mode": "node_depths",
            "init_std": 0.0305,
            "max_norm": 0.001
        },
        "post_encoder_position_embeddings": {
            "mode": "vanilla",
            "init_std": 0.0305
        },
        "attention": {
            "mode": "vanilla"
        },
        "scaffold_tasks": {
            "mode": "vanilla",
            "token_chance": 0.05,
            "on_task_data": true,
            "scaffold_weight": 0.3,
            "on_s2orc_itg_subset": false,
            "num_docs_per_shard": 200,
            "instances_ratio": 0.3
        },
        "fast_dev_run": false,
        "accelerator": "gpu",
        "precision": 32,
        "dataloader_num_workers": 7,
        "gradient_checkpointing": false,
        "use_cache": true,
        "num_sanity_val_steps": 0,
        "log_every_n_steps": 50,
        "random": {
            "seed": 635191,
            "deterministic_trainer": false
        },
        "task": {
            "task_name": "QASPER",
            "text_evidence_only": true,
            "deep_or_shallow": "deep",
            "count_missing_predictions": true
        },
        "model": {
            "model_name": "LongT5",
            "task_name": "QASPER",
            "num_beams": 4,
            "do_sample": false,
            "length_penalty": 1,
            "max_length": 100,
            "evidence": {
                "learn_evidence_detection": true,
                "evidence_detection_weight": 0.5,
                "use_evidence_loss_weights": false,
                "relevant_node_types": [
                    "p"
                ]
            },
            "max_steps": 10200,
            "min_steps": 10200,
            "val_check_interval": 4000,
            "batch_size": 1,
            "accumulate_grad_batches": 8,
            "learning_rate": 0.0001
        }
    },
    "hash": "3fd5-6f33",
    "stats": {
        "task-initialization.num-train-documents": 888,
        "task-initialization.num-dev-documents": 281,
        "task-initialization.num-test-documents": 416,
        "task-initialization.num-train-instances": 2675,
        "task-initialization.num-dev-instances": 1005,
        "task-initialization.num-test-instances": 1451,
        "task-initialization.evidence-statistics": {
            "0": 212372,
            "1": 4085
        }
    },
    "results_by_step": [
        [
            500,
            {
                "answer_f1": 0.29742766458718684,
                "answer_f1_by_type": {
                    "extractive": 0.3206882616621871,
                    "abstractive": 0.13547608257609972,
                    "boolean": 0.5316625853179949,
                    "none": 0.2911392405063291
                },
                "evidence_f1": 0.2529590144515517,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.24825628688806145,
                "multi_mean_rouge_2": 0.10435277225152484,
                "multi_mean_rouge_l": 0.23799793921249102,
                "multi_max_rouge_1": 0.30820782394453905,
                "multi_max_rouge_2": 0.1425229069368221,
                "multi_max_rouge_l": 0.29609893566019685,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "Masked Language Modeling (MLM), Translation Language Modeling (TLM), BRidge Language Modeling (BRLM)"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer is adopted for all translation models in our experiments. For the fair comparison, the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer is adopted for all translation models in our experiments."
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl, MultiUN"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), where English acts as the pivot language, its left side is the source language, and its right side is the target language."
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "articles of Armenian Wikipedia, The Armenian Soviet Encyclopedia, a subcorpus of Eastern Armenian National Corpus BIBREF12"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "Yes"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "topics such as abortion, climate change and abortion, to world news and relationship advice, to the future of artificial intelligence"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Unanswerable"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.29742766458718684,
                    "QASPER Evidence F1": 0.2529590144515517,
                    "QASPER R1": 0.30820782394453905,
                    "QASPER R2": 0.1425229069368221,
                    "QASPER RL": 0.29609893566019685
                }
            }
        ],
        [
            1001,
            {
                "answer_f1": 0.3282321293438638,
                "answer_f1_by_type": {
                    "extractive": 0.3594745542736546,
                    "abstractive": 0.15906750820141388,
                    "boolean": 0.5622636223560723,
                    "none": 0.27710843373493976
                },
                "evidence_f1": 0.3333537441000129,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.27336304071308126,
                "multi_mean_rouge_2": 0.12721405219998655,
                "multi_mean_rouge_l": 0.26137179745771694,
                "multi_max_rouge_1": 0.3390715283787654,
                "multi_max_rouge_2": 0.17154439517438255,
                "multi_max_rouge_l": 0.32529738935286584,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer is adopted for all translation models in our experiments. For the fair comparison, the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer is adopted for all translation models in our experiments. For the fair comparison, the Transformer-big model with 1024"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl, MultiUN"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), where English acts as the pivot language, its left side is the source language, and its right side is the target language"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "articles of Armenian Wikipedia, The Armenian Soviet Encyclopedia, a subcorpus of Eastern Armenian National Corpus BIBREF12, over a dozen Armenian news websites and blogs"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "Yes"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "subreddits are sub-communities on Reddit oriented around specific interests or topics, such as technology or politics. Sampling from Reddit as whole would bias the model towards the most commonly discussed content. But by sampling posts from individual subreddits, we can control the kinds of posts we use to train our model. To collect a diverse training dataset, we have randomly sampled 1000 posts each from the subreddits politics, business, science"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features. BOW and SENT provide baselines for the task. We compute BOW features using term frequency-inverse document frequency (TF-IDF) and category-based features by normalizing counts for each category by the number of words in each document. The BOW class"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Unanswerable"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3282321293438638,
                    "QASPER Evidence F1": 0.3333537441000129,
                    "QASPER R1": 0.3390715283787654,
                    "QASPER R2": 0.17154439517438255,
                    "QASPER RL": 0.32529738935286584
                }
            }
        ],
        [
            1502,
            {
                "answer_f1": 0.34581043847970394,
                "answer_f1_by_type": {
                    "extractive": 0.38856868017705154,
                    "abstractive": 0.15694990026400724,
                    "boolean": 0.560308383023026,
                    "none": 0.3132530120481928
                },
                "evidence_f1": 0.37680585394646665,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.28848536682094245,
                "multi_mean_rouge_2": 0.13113761835327303,
                "multi_mean_rouge_l": 0.27773084210046367,
                "multi_max_rouge_1": 0.35645410545728756,
                "multi_max_rouge_2": 0.17694905903891084,
                "multi_max_rouge_l": 0.3446761292285555,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "20 February 2018 dump of Armenian Wikipedia"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "Yes, we used IOB tagging scheme, with a total of 7 class tags: O, B-PER, I-PER, B-LOC, I-LOC, B-ORG, I-ORG"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "technology, politics, business, science, and AskReddit"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression model based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Unanswerable"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.34581043847970394,
                    "QASPER Evidence F1": 0.37680585394646665,
                    "QASPER R1": 0.35645410545728756,
                    "QASPER R2": 0.17694905903891084,
                    "QASPER RL": 0.3446761292285555
                }
            }
        ],
        [
            2003,
            {
                "answer_f1": 0.37060626396888136,
                "answer_f1_by_type": {
                    "extractive": 0.4043577087917278,
                    "abstractive": 0.19130333529117113,
                    "boolean": 0.5605288761422524,
                    "none": 0.3953488372093023
                },
                "evidence_f1": 0.4042504206683312,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.3060286105933667,
                "multi_mean_rouge_2": 0.13895482306381865,
                "multi_mean_rouge_l": 0.2930940031924632,
                "multi_max_rouge_1": 0.37889830424189086,
                "multi_max_rouge_2": 0.18767545339637676,
                "multi_max_rouge_l": 0.36430955054554603,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "traditional transfer learning, pivot-based method and multilingual NMT"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31 and MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "articles of Armenian Wikipedia, The Armenian Soviet Encyclopedia, a subcorpus of Eastern Armenian National Corpus BIBREF12"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "Yes"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "technology, politics, business, science, and AskReddit"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Kappa value among the annotators is 0.6033, indicating that the crowd annotators have moderate agreement on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on "
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.37060626396888136,
                    "QASPER Evidence F1": 0.4042504206683312,
                    "QASPER R1": 0.37889830424189086,
                    "QASPER R2": 0.18767545339637676,
                    "QASPER RL": 0.36430955054554603
                }
            }
        ],
        [
            2504,
            {
                "answer_f1": 0.36363895322227885,
                "answer_f1_by_type": {
                    "extractive": 0.40307088897440363,
                    "abstractive": 0.17231196401794668,
                    "boolean": 0.49791873693447813,
                    "none": 0.47126436781609193
                },
                "evidence_f1": 0.4107423459706163,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.3033575809549269,
                "multi_mean_rouge_2": 0.1346016700883615,
                "multi_mean_rouge_l": 0.29022950008733434,
                "multi_max_rouge_1": 0.37624760072185803,
                "multi_max_rouge_2": 0.18197487353235522,
                "multi_max_rouge_l": 0.36123536881515866,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "articles of Armenian Wikipedia, The Armenian Soviet Encyclopedia, a subcorpus of Eastern Armenian National Corpus BIBREF12"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "BOW+LING"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Unanswerable"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.36363895322227885,
                    "QASPER Evidence F1": 0.4107423459706163,
                    "QASPER R1": 0.37624760072185803,
                    "QASPER R2": 0.18197487353235522,
                    "QASPER RL": 0.36123536881515866
                }
            }
        ],
        [
            3005,
            {
                "answer_f1": 0.3682865648994631,
                "answer_f1_by_type": {
                    "extractive": 0.40299192672198436,
                    "abstractive": 0.1908965943909942,
                    "boolean": 0.5079008437570539,
                    "none": 0.43956043956043955
                },
                "evidence_f1": 0.4225091810007018,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.30409669171857734,
                "multi_mean_rouge_2": 0.13813354334733186,
                "multi_mean_rouge_l": 0.2914616009404302,
                "multi_max_rouge_1": 0.3762732931333395,
                "multi_max_rouge_2": 0.18702456191015537,
                "multi_max_rouge_l": 0.36262863389390526,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31, MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "the articles of Armenian Wikipedia, The Armenian Soviet Encyclopedia, a subcorpus of Eastern Armenian National Corpus BIBREF12"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "technology, politics, business, science, and AskReddit"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "BOW+LING"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "The average Kappa value among the annotators is 0.6033, indicating that the crowd annotators have moderate agreement on identifying entities on identifying entities on DL-PS"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3682865648994631,
                    "QASPER Evidence F1": 0.4225091810007018,
                    "QASPER R1": 0.3762732931333395,
                    "QASPER R2": 0.18702456191015537,
                    "QASPER RL": 0.36262863389390526
                }
            }
        ],
        [
            3506,
            {
                "answer_f1": 0.36836183305209497,
                "answer_f1_by_type": {
                    "extractive": 0.3967475447634037,
                    "abstractive": 0.1525535406037065,
                    "boolean": 0.5650022492127755,
                    "none": 0.5268817204301075
                },
                "evidence_f1": 0.4321041120294851,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.30611000672172234,
                "multi_mean_rouge_2": 0.13441950009570489,
                "multi_mean_rouge_l": 0.2943944710395931,
                "multi_max_rouge_1": 0.3778067430126986,
                "multi_max_rouge_2": 0.1798862720373913,
                "multi_max_rouge_l": 0.36462594391339226,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "pivot-based method, multilingual NMT"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl, MultiUN"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14 that uses bidirectional LSTM cells for character-based feature extraction and CRF, described in Guillaume Genthial's Sequence Tagging with Tensorflow blog post BIBREF15"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "Guns, LGBT, religion, technology, politics"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "BOW+LING model trained on the full Reddit dataset to millions of new unannotated posts, labeling these posts with a probability of dogmatism according to the classifier (0=non-dogmatic, 1=dogmatic), mutual information BIBREF13 between these links"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "The average Kappa value of the annotators is 0.6033, indicating that the crowd annotators have moderate agreement on identifying entities on identifying entities on a scale from 1-5."
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.36836183305209497,
                    "QASPER Evidence F1": 0.4321041120294851,
                    "QASPER R1": 0.3778067430126986,
                    "QASPER R2": 0.1798862720373913,
                    "QASPER RL": 0.36462594391339226
                }
            }
        ],
        [
            4006,
            {
                "answer_f1": 0.3839636692545022,
                "answer_f1_by_type": {
                    "extractive": 0.41039526853152714,
                    "abstractive": 0.17804306582667934,
                    "boolean": 0.5327941124030775,
                    "none": 0.5729166666666666
                },
                "evidence_f1": 0.43994101315321316,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.31856853198393686,
                "multi_mean_rouge_2": 0.139137956854465,
                "multi_mean_rouge_l": 0.30499549696296463,
                "multi_max_rouge_1": 0.3925080507103135,
                "multi_max_rouge_2": 0.1872761497487819,
                "multi_max_rouge_l": 0.37680826662172107,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl, MultiUN"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "technology, politics, religion, AskReddit, and 1000 additional posts from the Reddit frontpage"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "BOW+LING, logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "The average Kappa value among the annotators is 0.6033, indicating that the crowd annotators have moderate agreement on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities on identifying entities"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3839636692545022,
                    "QASPER Evidence F1": 0.43994101315321316,
                    "QASPER R1": 0.3925080507103135,
                    "QASPER R2": 0.1872761497487819,
                    "QASPER RL": 0.37680826662172107
                }
            }
        ],
        [
            4508,
            {
                "answer_f1": 0.369871683130025,
                "answer_f1_by_type": {
                    "extractive": 0.39926357069806107,
                    "abstractive": 0.18338583206617534,
                    "boolean": 0.5426377118644068,
                    "none": 0.4772727272727273
                },
                "evidence_f1": 0.4460669036238561,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.30686009055553487,
                "multi_mean_rouge_2": 0.13531696794998108,
                "multi_mean_rouge_l": 0.29371815874027124,
                "multi_max_rouge_1": 0.3782820037780419,
                "multi_max_rouge_2": 0.18251147715664182,
                "multi_max_rouge_l": 0.3636595685697722,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "Masked Language Modeling (MLM), Translation Language Modeling (TLM), BRidge Language Modeling (BRLM)"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31 and MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "four languages: English (En), Arabic (Ar), Spanish (Es), and Russian (Ru)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "guns, LGBT, religion, politics, AskReddit, and 1000 additional posts from the Reddit frontpage"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "The average Kappa value among the annotators is 0.6033, indicating that the crowd annotators have moderate agreement on identifying entities on identifying entities on a scale of 1-5."
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.369871683130025,
                    "QASPER Evidence F1": 0.4460669036238561,
                    "QASPER R1": 0.3782820037780419,
                    "QASPER R2": 0.18251147715664182,
                    "QASPER RL": 0.3636595685697722
                }
            }
        ],
        [
            5008,
            {
                "answer_f1": 0.3777732828579029,
                "answer_f1_by_type": {
                    "extractive": 0.41599877335745405,
                    "abstractive": 0.18592963641576898,
                    "boolean": 0.5666666666666667,
                    "none": 0.4117647058823529
                },
                "evidence_f1": 0.4327854333563235,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.3141486930136762,
                "multi_mean_rouge_2": 0.14086211890851744,
                "multi_mean_rouge_l": 0.3011320664711529,
                "multi_max_rouge_1": 0.38838261748140257,
                "multi_max_rouge_2": 0.19236455454288287,
                "multi_max_rouge_l": 0.37276104980614827,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "traditional transfer learning, pivot-based method and multilingual NMT"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "traditional transfer learning, pivot-based method and multilingual NMT"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31 and MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "guns, LGBT"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "a logistic regression model based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "The average Kappa value among the annotators is 0.6033, indicating that the crowd annotators have moderate agreement on identifying entities on identifying entities on a scale of 1-5."
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3777732828579029,
                    "QASPER Evidence F1": 0.4327854333563235,
                    "QASPER R1": 0.38838261748140257,
                    "QASPER R2": 0.19236455454288287,
                    "QASPER RL": 0.37276104980614827
                }
            }
        ],
        [
            5510,
            {
                "answer_f1": 0.37142702634164715,
                "answer_f1_by_type": {
                    "extractive": 0.4030617618424036,
                    "abstractive": 0.19213494257876523,
                    "boolean": 0.591195174591228,
                    "none": 0.36904761904761907
                },
                "evidence_f1": 0.440541243400631,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.3090373448064121,
                "multi_mean_rouge_2": 0.13387278014735773,
                "multi_mean_rouge_l": 0.2966160073786122,
                "multi_max_rouge_1": 0.3800877886357776,
                "multi_max_rouge_2": 0.181549127594458,
                "multi_max_rouge_l": 0.36572800714016757,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "traditional transfer learning, pivot-based method and multilingual NMT"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31, MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14 that uses bidirectional LSTM cells for character-based feature extraction and CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "guns, LGBT"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "a logistic regression model based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "0.8320 on DL-PS and 0.7194 on E-commerce dataset"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.37142702634164715,
                    "QASPER Evidence F1": 0.440541243400631,
                    "QASPER R1": 0.3800877886357776,
                    "QASPER R2": 0.181549127594458,
                    "QASPER RL": 0.36572800714016757
                }
            }
        ],
        [
            6010,
            {
                "answer_f1": 0.3858271621865769,
                "answer_f1_by_type": {
                    "extractive": 0.41637902217809425,
                    "abstractive": 0.1967749914300889,
                    "boolean": 0.575,
                    "none": 0.47191011235955055
                },
                "evidence_f1": 0.4574206483633039,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.32129951723631545,
                "multi_mean_rouge_2": 0.14321269896785876,
                "multi_mean_rouge_l": 0.3079765491391522,
                "multi_max_rouge_1": 0.39511494509425926,
                "multi_max_rouge_2": 0.19448620553331414,
                "multi_max_rouge_l": 0.3804425418882458,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "traditional transfer learning, pivot-based method and multilingual NMT"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31, MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "guns, LGBT, religion, technology, AskReddit, and 1000 additional posts from the Reddit frontpage"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "The average Kappa value among the annotators is 0.6033, indicating that the crowd annotators have moderate agreement on identifying entities on a scale of 1-5."
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3858271621865769,
                    "QASPER Evidence F1": 0.4574206483633039,
                    "QASPER R1": 0.39511494509425926,
                    "QASPER R2": 0.19448620553331414,
                    "QASPER RL": 0.3804425418882458
                }
            }
        ],
        [
            6511,
            {
                "answer_f1": 0.38147599212462796,
                "answer_f1_by_type": {
                    "extractive": 0.4028111367810926,
                    "abstractive": 0.19736295276993018,
                    "boolean": 0.5969681990443236,
                    "none": 0.4588235294117647
                },
                "evidence_f1": 0.4616945130308489,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.32063662311378377,
                "multi_mean_rouge_2": 0.14175425551105542,
                "multi_mean_rouge_l": 0.30758967097389284,
                "multi_max_rouge_1": 0.39280775398891604,
                "multi_max_rouge_2": 0.1909291408598789,
                "multi_max_rouge_l": 0.3779335545221096,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivot-based method, transfer learning, multilingual NMT, and unsupervised NMT"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31, MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, Char-biLSTM+biLSTM+CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "20 February 2018 dump of Armenian Wikipedia"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "technology, politics, religion, healthcare, askReddit, world news and relationship advice"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Accuracy not available: Kappa value 0.6033"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.38147599212462796,
                    "QASPER Evidence F1": 0.4616945130308489,
                    "QASPER R1": 0.39280775398891604,
                    "QASPER R2": 0.1909291408598789,
                    "QASPER RL": 0.3779335545221096
                }
            }
        ],
        [
            7012,
            {
                "answer_f1": 0.3854722924480749,
                "answer_f1_by_type": {
                    "extractive": 0.399478488516869,
                    "abstractive": 0.19037842407693512,
                    "boolean": 0.5985958485958486,
                    "none": 0.5494505494505495
                },
                "evidence_f1": 0.476308484238323,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.32242523729787986,
                "multi_mean_rouge_2": 0.13361162082088182,
                "multi_mean_rouge_l": 0.31071672319926025,
                "multi_max_rouge_1": 0.39533928626170967,
                "multi_max_rouge_2": 0.1854510816968182,
                "multi_max_rouge_l": 0.3825555940843815,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "Masked Language Modeling (MLM), Translation Language Modeling (TLM)"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31, MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "Guns, LGBT"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Average Kappa value of 0.6033"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3854722924480749,
                    "QASPER Evidence F1": 0.476308484238323,
                    "QASPER R1": 0.39533928626170967,
                    "QASPER R2": 0.1854510816968182,
                    "QASPER RL": 0.3825555940843815
                }
            }
        ],
        [
            7513,
            {
                "answer_f1": 0.3713713438791619,
                "answer_f1_by_type": {
                    "extractive": 0.40688212603070995,
                    "abstractive": 0.19743503516112904,
                    "boolean": 0.5313012127171419,
                    "none": 0.42391304347826086
                },
                "evidence_f1": 0.4677962896959253,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.30991504551968374,
                "multi_mean_rouge_2": 0.13732490898249605,
                "multi_mean_rouge_l": 0.2961119098222747,
                "multi_max_rouge_1": 0.38169288771823806,
                "multi_max_rouge_2": 0.1846943021989177,
                "multi_max_rouge_l": 0.3656049285081503,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT), cross-lingual transfer without pretraining"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31, MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14 that uses bidirectional LSTM cells for character-based feature extraction and CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "articles of Armenian Wikipedia, The Armenian Soviet Encyclopedia, a subcorpus of Eastern Armenian National Corpus"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "technology, politics, religion, askReddit, and 1000 additional posts from the Reddit frontpage"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "a linear regression model where we predict each user's average dogmatism level. This model takes two features, the dogmatism levels of A1 and B, and predicts the dogmatism response of A2. If B's dogmatism has no effect on A's response, the coefficient that corresponds to B will not be significant in the model. Alternatively, if B's dogmatism does have some effect, it will be captured by the"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "0.8320 on DL-PS and 0.7194 on DL-PS"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3713713438791619,
                    "QASPER Evidence F1": 0.4677962896959253,
                    "QASPER R1": 0.38169288771823806,
                    "QASPER R2": 0.1846943021989177,
                    "QASPER RL": 0.3656049285081503
                }
            }
        ],
        [
            8014,
            {
                "answer_f1": 0.3651705737674858,
                "answer_f1_by_type": {
                    "extractive": 0.4030432618113355,
                    "abstractive": 0.20118994551507932,
                    "boolean": 0.5462184873949579,
                    "none": 0.32926829268292684
                },
                "evidence_f1": 0.45945305236687367,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.3046727832427756,
                "multi_mean_rouge_2": 0.13911739124661812,
                "multi_mean_rouge_l": 0.29028526127768317,
                "multi_max_rouge_1": 0.37488002835520806,
                "multi_max_rouge_2": 0.1885881866716415,
                "multi_max_rouge_l": 0.35887894690975025,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT), cross-lingual transfer without pretraining"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31, MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14 that uses bidirectional LSTM cells for character-based feature extraction and CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "ilur.am"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "from climate change and abortion, to world news and relationship advice, to the future of artificial intelligence"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "model takes two features, the dogmatism levels of A1 and B, and predicts the dogmatism response of A2. If B's dogmatism has no effect on A's response, the coefficient that corresponds to B will not be significant in the model. Alternatively, if B's dogmatism does have some effect, it will be captured by the model's coefficient."
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Average Kappa value of 0.6033"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3651705737674858,
                    "QASPER Evidence F1": 0.45945305236687367,
                    "QASPER R1": 0.37488002835520806,
                    "QASPER R2": 0.1885881866716415,
                    "QASPER RL": 0.35887894690975025
                }
            }
        ],
        [
            8515,
            {
                "answer_f1": 0.3863123411878324,
                "answer_f1_by_type": {
                    "extractive": 0.4139312726668997,
                    "abstractive": 0.19728528176719892,
                    "boolean": 0.5671035997072327,
                    "none": 0.48459330143540663
                },
                "evidence_f1": 0.45831437829241234,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.3199334681586046,
                "multi_mean_rouge_2": 0.1457418566209126,
                "multi_mean_rouge_l": 0.3071011374858306,
                "multi_max_rouge_1": 0.3951521517541625,
                "multi_max_rouge_2": 0.1965928813449235,
                "multi_max_rouge_l": 0.3804151943815835,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT), cross-lingual transfer without pretraining"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31 and MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14 that uses bidirectional LSTM cells for character-based feature extraction and CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "20 February 2018 dump of Armenian Wikipedia"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "model takes two features, the dogmatism levels of A1 and B, and predicts the dogmatism response of A2. If B's dogmatism has no effect on A's response, the coefficient that corresponds to B will not be significant in the model. Alternatively, if B's dogmatism does have some effect, it will be captured by the model's coefficient."
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Average Kappa value of 0.6033"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3863123411878324,
                    "QASPER Evidence F1": 0.45831437829241234,
                    "QASPER R1": 0.3951521517541625,
                    "QASPER R2": 0.1965928813449235,
                    "QASPER RL": 0.3804151943815835
                }
            }
        ],
        [
            9016,
            {
                "answer_f1": 0.3772635018515868,
                "answer_f1_by_type": {
                    "extractive": 0.39755685839665905,
                    "abstractive": 0.1903985952915544,
                    "boolean": 0.5885020674936641,
                    "none": 0.4772727272727273
                },
                "evidence_f1": 0.4585580174386147,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.3121735841965664,
                "multi_mean_rouge_2": 0.13539267939830932,
                "multi_mean_rouge_l": 0.29938579228328865,
                "multi_max_rouge_1": 0.3847692214697735,
                "multi_max_rouge_2": 0.18515168773821208,
                "multi_max_rouge_l": 0.3710896122665986,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivot-based method, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "traditional transfer learning, pivot-based method and multilingual NMT, Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31, MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14 that uses bidirectional LSTM cells for character-based feature extraction and CRF"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "20 February 2018 dump of Armenian Wikipedia"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "The subreddits politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "0.8320 on Dialog and 0.9148 on E-commerce domain"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3772635018515868,
                    "QASPER Evidence F1": 0.4585580174386147,
                    "QASPER R1": 0.3847692214697735,
                    "QASPER R2": 0.18515168773821208,
                    "QASPER RL": 0.3710896122665986
                }
            }
        ],
        [
            9517,
            {
                "answer_f1": 0.3796274916049633,
                "answer_f1_by_type": {
                    "extractive": 0.3885341308489647,
                    "abstractive": 0.17558129507617404,
                    "boolean": 0.6153846153846154,
                    "none": 0.5652173913043478
                },
                "evidence_f1": 0.4542764594379588,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.3149599730120306,
                "multi_mean_rouge_2": 0.1267409593169513,
                "multi_mean_rouge_l": 0.3025342322138787,
                "multi_max_rouge_1": 0.3891268026293381,
                "multi_max_rouge_2": 0.1749047603549237,
                "multi_max_rouge_l": 0.37526101992686567,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT), cross-lingual transfer without pretraining"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31, MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr), Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "technology, politics, religion, askReddit, and 1000 additional posts from the Reddit frontpage"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our previous analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "0.8320 on DL-PS, 0.7194 on Dialog-PS, 0.7194 on E-commerce domain"
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3796274916049633,
                    "QASPER Evidence F1": 0.4542764594379588,
                    "QASPER R1": 0.3891268026293381,
                    "QASPER R2": 0.1749047603549237,
                    "QASPER RL": 0.37526101992686567
                }
            }
        ],
        [
            10018,
            {
                "answer_f1": 0.3682347738861153,
                "answer_f1_by_type": {
                    "extractive": 0.4133624487970799,
                    "abstractive": 0.19221559261084767,
                    "boolean": 0.5,
                    "none": 0.38636363636363635
                },
                "evidence_f1": 0.4546672075090358,
                "num_missing_predictions": 0,
                "multi_mean_rouge_1": 0.3081440701811801,
                "multi_mean_rouge_2": 0.13981480514890715,
                "multi_mean_rouge_l": 0.2943549213517246,
                "multi_max_rouge_1": 0.38008902580753384,
                "multi_max_rouge_2": 0.19132386656939096,
                "multi_max_rouge_l": 0.36477999518000837,
                "samples": [
                    [
                        [
                            "BIBREF19, BIBREF20",
                            "multilingual NMT (MNMT) BIBREF19"
                        ],
                        "pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16"
                    ],
                    [
                        [
                            "pivoting, pivoting$_{\\rm m}$",
                            "firstly translates a source language into the pivot language which is later translated to the target language"
                        ],
                        "the Transformer-big model with 1024 embedding/hidden units, 4096 feed-forward filter size, 6 layers and 8 heads per layer"
                    ],
                    [
                        [
                            "Europarl, MultiUN",
                            "Europarl BIBREF31, MultiUN BIBREF32"
                        ],
                        "Europarl BIBREF31 and MultiUN BIBREF32"
                    ],
                    [
                        [
                            "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
                            "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation"
                        ],
                        "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)"
                    ],
                    [
                        [
                            "Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer",
                            "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"
                        ],
                        "Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14"
                    ],
                    [
                        [
                            "ilur.am",
                            "links between Wikipedia articles to generate sequences of named-entity annotated tokens"
                        ],
                        "Unanswerable"
                    ],
                    [
                        [
                            "No",
                            "No"
                        ],
                        "No"
                    ],
                    [
                        [
                            "politics, business, science, and AskReddit, and 1000 additional posts from the Reddit frontpage. ",
                            "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit"
                        ],
                        "technology, politics, religion, askReddit, and 1000 additional posts from the Reddit frontpage"
                    ],
                    [
                        [
                            "logistic regression models",
                            "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."
                        ],
                        "A logistic regression model trained on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our previous analyses (LING), and combinations of these features"
                    ],
                    [
                        [
                            "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
                            "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"
                        ],
                        "Across 16 datasets, the best performing proposed model (CNN) achieved an average of 363% log-likelihood on NER and 36.93% log-likelihood on DL-PS."
                    ]
                ],
                "table_entries": {
                    "QASPER Answer F1": 0.3682347738861153,
                    "QASPER Evidence F1": 0.4546672075090358,
                    "QASPER R1": 0.38008902580753384,
                    "QASPER R2": 0.19132386656939096,
                    "QASPER RL": 0.36477999518000837
                }
            }
        ]
    ],
    "best_num_steps": 7012,
    "test_result": {
        "answer_f1": 0.44021065164429096,
        "answer_f1_by_type": {
            "extractive": 0.47631636337553535,
            "abstractive": 0.20191957488507342,
            "boolean": 0.6488320208415618,
            "none": 0.44881889763779526
        },
        "evidence_f1": 0.5338797552641598,
        "num_missing_predictions": 0,
        "multi_mean_rouge_1": 0.32790040328444525,
        "multi_mean_rouge_2": 0.14145179345286704,
        "multi_mean_rouge_l": 0.3169186109603061,
        "multi_max_rouge_1": 0.44690991697531324,
        "multi_max_rouge_2": 0.21603244462208496,
        "multi_max_rouge_l": 0.43397525648325763,
        "samples": [
            [
                [
                    " 3,044 sentences in 100 dialogs",
                    "220 human-human dialogs",
                    "220 human-human dialogs. , 3,044 sentences in 100 dialogs",
                    "220 human-human dialogs. The average conversation length is 12.45 turns and the average utterance length is 11.13 words. ",
                    "220 human-human dialogs",
                    "3,044 sentences in 100 dialogs"
                ],
                "1,017 dialogs"
            ],
            [
                [
                    "using a role-playing task on the Amazon Mechanical Turk platform and collecting typed conversations",
                    "Separate on-task and off task intents and annotate on task for data set specific intents, while annotating  off task intents with a fixed set of general intents.",
                    "On-task dialog are annotated as on-task intents , the other dialog are annotated as pre-defined off-task intents.",
                    "separate on-task and off-task intents, on-task intents are key actions that can vary among different tasks, we need to specifically define on-task intents for each task, off-task content is too general to design task-specific intents, we choose common dialog acts as the categories",
                    "we design a hierarchical intent annotation scheme for non-collaborative tasks. We first separate on-task and off-task intents. As on-task intents are key actions that can vary among different tasks, we need to specifically define on-task intents for each task. On the other hand, since off-task content is too general to design task-specific intents, we choose common dialog acts as the categories. , In the intent annotation scheme shown in Table TABREF2, we list the designed intent annotation scheme for the newly collected AntiScam dataset and the PersuasionForGood dataset. We first define on-task intents for the datasets, which are key actions in the task. Since our AntiScam focuses on understanding and reacting towards elicitations, we define elicitation, providing_information and refusal as on-task intents. In the PersuasionForGood dataset, we define nine on-task intents in Table TABREF2 based on the original PersuasionForGood dialog act annotation scheme, For specific tasks, we also design a semantic slot annotation scheme for annotating sentences based on their semantic content. We identify 13 main semantic slots in the anti-scam task, for example, credit card numbers. We present a detailed semantic slot annotation in Table TABREF3. Following BIBREF1, we segment each conversation turn into single sentences and then annotate each sentence rather than turns.",
                    "using a hierarchical scheme where on-task intents uses task-related intents for representation and off-task intents chooses dialog acts that convey the syntax information"
                ],
                "on-task intents for the datasets, which are key actions in the task, we define elicitation, providing_information and refusal as on-task intents, we define nine on-task intents in Table TABREF2 based on the original PersuasionForGood dialog act annotation scheme"
            ],
            [
                [
                    "TransferTransfo and Hybrid ",
                    "TransferTransfo,  hybrid model",
                    "TransferTransfo, Hybrid",
                    "TransferTransfo, Hybrid",
                    "TransferTransfo The vanilla TransferTransfo framework, Hybrid Following BIBREF4 yu2017learning, we also build a hybrid dialog system by combining vanilla TransferTransfo and MISSA",
                    "TransferTransfo, Hybrid"
                ],
                "TransferTransfo, Hybrid Following BIBREF4 yu2017learning, we also build a hybrid dialog system by combining vanilla TransferTransfo and MISSA"
            ],
            [
                [
                    "Perplexity, Response-Intent Prediction (RIP), Response-Slot Prediction (RSP), Extended Response-Intent Prediction (ERIP) , Extended Response-Slot Prediction (ERSP) , Fluency, Coherence , Engagement, Dialog length , Task Success Score (TaskSuc)",
                    "Perplexity , Response-Intent Prediction (RIP), Response-Slot Prediction (RSP), Extended Response-Intent Prediction (ERIP), Extended Response-Slot Prediction (ERSP), Fluency , Coherence , Engagement , Dialog length (Length) , Task Success Score (TaskSuc)",
                    "Fluency Fluency is used to explore different models' language generation quality.\n\nCoherence Different from single sentence's fluency, coherence focuses more on the logical consistency between sentences in each turn.\n\nEngagement In the anti-scam scenario, one of our missions is to keep engaging with the attackers to waste their time. So we directly ask volunteers (attackers) to what extend they would like to continue chatting with the system.\n\nDialog length (Length) Engagement is a subjective metric. Anti-scam system's goal is to engage user in the conversation longer in order to limit their harm to other potential victims. So we count the dialog length as another metric to evaluate system performance.\n\nTask Success Score (TaskSuc) The other goal of the anti-scam system is to elicit attacker's personal information. We count the average type of information (name, address and phone number) that the system obtained from attackers as the task success score.",
                    "Automatic evaluation metrics (Perplexity (PPl), Response-Intent Prediction (RIP), Response-Slot Prediction(RSP), Extended Response-Intent Prediction(ERIP),  Extended Response-Slot Prediction (ERSP)) and Human Evaluation Metrics (Fluency, Coherence, Engagement, Lenhth, TaskSuc)",
                    "Automatic metrics used: Perplexity, RIP, RSP, ERIP ERSP.\nHuman evaluation metrics used: Fluency, Coherence, Engagement, Dialog length and Task Success Score."
                ],
                "Fluency Fluency, Coherence, Engagement, Task Success Score (TaskSuc) The other goal of the anti-scam system is to elicit attacker's personal information. We count the average type of information (name, address and phone number) that the system obtained from attackers as the task success score"
            ],
            [
                [
                    "Unanswerable",
                    "The model improves the state of the art performance for the ISTEX dataset (F1 micro: 0.870, F1 macro: 0.858) and for the Microposts 2016 dataset (F1 micro:  0.087).",
                    "The micro and macro f1-scores of this model are 0.482 and 0.399 on the AIDA-CoNLL dataset, 0.087 and 0.515 on the Microposts 2016 dataset, 0.870 and 0.858 on the ISTEX-1000 dataset, 0.335 and 0.310 on the RSS-500 dataset",
                    "The accuracy ",
                    "Unanswerable"
                ],
                "micro and macro F1 scores on test sets, with GERBIL's weak annotation match method"
            ],
            [
                [
                    "two state-of-the-art early rumour detection baselines Liu et. al (2015) and Yang et. al (2012), which we re-implemented., Yang et. al (2012), dubbed Yang, because they proposed a feature set for early detection tailored to Sina Weibo and were used as a state-of-the-art baseline before by Liu et. al (2015). The algorithm by Liu et. al (2015), dubbed Liu, is said to operate in real-time and outperformed Yang, when only considering features available on Twitter.",
                    "Liu et. al (2015), Yang et. al (2012)",
                    "They compare against two other methods that apply message-,user-, topic- and propagation-based features and rely on an SVM classifier. One perform early rumor detection and operates with a delay of 24 hrs, while the other requires a cluster of 5 repeated messages to judge them for rumors.",
                    "Liu et. al (2015) , Yang et. al (2012)",
                    "Liu et al. (2015) and Yang et al. (2012)"
                ],
                "Liu et. al (2015) and Yang et. al (2012)"
            ],
            [
                [
                    "accuracy to evaluate effectiveness, Detection Error Trade-off (DET) curves, which show the trade-off between miss and false alarm probability, throughput per second",
                    "The metrics are accuracy, detection error trade-off curves and computing efficiency",
                    "accuracy , Detection Error Trade-off (DET) curves, efficiency of computing the proposed features, measured by the throughput per second",
                    "accuracy to evaluate effectiveness, Detection Error Trade-off (DET) curves, which show the trade-off between miss and false alarm probability, throughput per second",
                    "Accuracy compared to two state-of-the-art baselines"
                ],
                "accuracy"
            ],
            [
                [
                    "No. They additionally use similarity to previously detected rumors to make the decision of whether a document is likely to be a rumor"
                ],
                "No"
            ],
            [
                [
                    "Yes",
                    "Yes",
                    "Yes",
                    "Yes, consisting of trusted resources, rumours and non-rumours",
                    "Yes"
                ],
                "Yes"
            ],
            [
                [
                    "Chinese",
                    "Mandarin Chinese",
                    "Chinese",
                    "Mandarin Chinese (see table 3)",
                    "Chinese"
                ],
                "Chinese"
            ]
        ],
        "table_entries": {
            "QASPER Answer F1": 0.44021065164429096,
            "QASPER Evidence F1": 0.5338797552641598,
            "QASPER R1": 0.44690991697531324,
            "QASPER R2": 0.21603244462208496,
            "QASPER RL": 0.43397525648325763
        }
    },
    "total_time": 102313.94338393211
}