{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import difflib\n",
    "import json\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "from intertext_graph.itgraph import IntertextDocument\n",
    "\n",
    "import config\n",
    "from histogram import histogram\n",
    "from metadata_analyzer import parse_json_object\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l) / len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# QASPER Metadata Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# configuration\n",
    "config.load_config_json_file(\"../path_config_local.json\", include_in_hash=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1585 documents.\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "documents = []\n",
    "path = os.path.join(config.get(\"path.QASPER-ITG\"), \"train.jsonl\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for document_json_str in file:\n",
    "        with StringIO(document_json_str) as f:\n",
    "            document = IntertextDocument.load_json(f)\n",
    "            documents.append(document)\n",
    "path = os.path.join(config.get(\"path.QASPER-ITG\"), \"dev.jsonl\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for document_json_str in file:\n",
    "        with StringIO(document_json_str) as f:\n",
    "            document = IntertextDocument.load_json(f)\n",
    "            documents.append(document)\n",
    "path = os.path.join(config.get(\"path.QASPER-ITG\"), \"test.jsonl\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for document_json_str in file:\n",
    "        with StringIO(document_json_str) as f:\n",
    "            document = IntertextDocument.load_json(f)\n",
    "            documents.append(document)\n",
    "print(f\"Loaded {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Document Metadata Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/1x [\n",
      "      1585/1585x {\n",
      "        'qas': \n",
      "          1585/1585x [\n",
      "              5049/5049x {\n",
      "                'topic_background': (1): 3725/5049x non-empty string || (2): 1324/5049x empty string\n",
      "                'question_id': 5049/5049x non-empty string\n",
      "                'question': 5049/5049x non-empty string\n",
      "                'search_query': (1): 3498/5049x empty string || (2): 1551/5049x non-empty string\n",
      "                'question_writer': 5049/5049x non-empty string\n",
      "                'nlp_background': (1): 3876/5049x non-empty string || (2): 1173/5049x empty string\n",
      "                'paper_read': (1): 3725/5049x non-empty string || (2): 1324/5049x empty string\n",
      "                'answers': \n",
      "                  5049/5049x [\n",
      "                      7993/7993x {\n",
      "                        'answer': \n",
      "                          7993/7993x {\n",
      "                            'evidence': 7993/7993x [12761/12761x non-empty string]\n",
      "                            'yes_no': (1): 6883/7993x null || (2): 1110/7993x number\n",
      "                            'highlighted_evidence': 7993/7993x [10706/10706x non-empty string]\n",
      "                            'unanswerable': 7993/7993x number\n",
      "                            'free_form_answer': (1): 1931/7993x non-empty string || (2): 6062/7993x empty string\n",
      "                            'extractive_spans': 7993/7993x [8174/8174x non-empty string]\n",
      "                          }\n",
      "                        'worker_id': 7993/7993x non-empty string\n",
      "                        'annotation_id': 7993/7993x non-empty string\n",
      "                      }\n",
      "                  ]\n",
      "              }\n",
      "          ]\n",
      "        'arxiv_id': 1585/1585x non-empty string\n",
      "        'ix_counter': 1585/1585x number\n",
      "      }\n",
      "  ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = [document.meta for document in documents]\n",
    "print(parse_json_object(metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Node Metadata Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/1x [\n",
      "      (1):\n",
      "      109751/121115x {\n",
      "        'is_evidence_for': \n",
      "          109751/109751x [\n",
      "              11663/11663x {\n",
      "                'evidence_ix': 11663/11663x number\n",
      "                'annotation_id': 11663/11663x non-empty string\n",
      "              }\n",
      "          ]\n",
      "      }\n",
      "\n",
      "      (2):\n",
      "      11364/121115x {\n",
      "        'is_evidence_for': \n",
      "          11364/11364x [\n",
      "              1092/1092x {\n",
      "                'evidence_ix': 1092/1092x number\n",
      "                'annotation_id': 1092/1092x non-empty string\n",
      "              }\n",
      "          ]\n",
      "        'file': 11364/11364x non-empty string\n",
      "      }\n",
      "  ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = [node.meta for document in documents for node in document.nodes]\n",
    "print(parse_json_object(metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prompts and Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Number of questions per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    # questions  # documents with this many questions\n3             1                                   278\n2             2                                   320\n0             3                                   371\n1             4                                   325\n4             5                                   149\n5             6                                    81\n6             7                                    28\n7             8                                    19\n8             9                                     7\n9            10                                     3\n11           11                                     2\n10           12                                     2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># questions</th>\n      <th># documents with this many questions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>278</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>320</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>371</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>325</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>12</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_questions = collections.Counter()\n",
    "for document in documents:\n",
    "    num_questions[len(document.meta[\"qas\"])] += 1\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"# questions\": [x for x, _  in num_questions.most_common()],\n",
    "    \"# documents with this many questions\": [x for _, x in num_questions.most_common()]\n",
    "}).sort_values(\"# questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Number of answers per question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   # answers  # questions with this many answers\n0          1                                2796\n1          2                                1648\n2          3                                 531\n3          4                                  65\n4          5                                   6\n5          6                                   3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># answers</th>\n      <th># questions with this many answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2796</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1648</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>531</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_answers = collections.Counter()\n",
    "for document in documents:\n",
    "    for qas in document.meta[\"qas\"]:\n",
    "        num_answers[len(qas[\"answers\"])] += 1\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"# answers\": [count for count, _  in num_answers.most_common()],\n",
    "    \"# questions with this many answers\": [count for _, count in num_answers.most_common()]\n",
    "}).sort_values(\"# answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                               min        avg  max   total\n# characters                     4  50.497326  176  254961\n# whitespace-separated tokens    1   8.139037   25   41094",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min</th>\n      <th>avg</th>\n      <th>max</th>\n      <th>total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th># characters</th>\n      <td>4</td>\n      <td>50.497326</td>\n      <td>176</td>\n      <td>254961</td>\n    </tr>\n    <tr>\n      <th># whitespace-separated tokens</th>\n      <td>1</td>\n      <td>8.139037</td>\n      <td>25</td>\n      <td>41094</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_lengths = [len(qas[\"question\"]) for document in documents for qas in document.meta[\"qas\"]]\n",
    "token_lengths = [len(qas[\"question\"].split()) for document in documents for qas in document.meta[\"qas\"]]\n",
    "\n",
    "pd.DataFrame(\n",
    "    index=[\"# characters\", \"# whitespace-separated tokens\"],\n",
    "    data={\n",
    "        \"min\": [min(char_lengths), min(token_lengths)],\n",
    "        \"avg\": [mean(char_lengths), mean(token_lengths)],\n",
    "        \"max\": [max(char_lengths), max(token_lengths)],\n",
    "        \"total\": [sum(char_lengths), sum(token_lengths)]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer Lengths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "        num\n0-4    3671\n5-9    1335\n10-14   900\n15-19   665\n20-24   442\n25-29   268\n30-34   192\n35-39   111\n40-44    93\n45-49    71\n≥50     245",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0-4</th>\n      <td>3671</td>\n    </tr>\n    <tr>\n      <th>5-9</th>\n      <td>1335</td>\n    </tr>\n    <tr>\n      <th>10-14</th>\n      <td>900</td>\n    </tr>\n    <tr>\n      <th>15-19</th>\n      <td>665</td>\n    </tr>\n    <tr>\n      <th>20-24</th>\n      <td>442</td>\n    </tr>\n    <tr>\n      <th>25-29</th>\n      <td>268</td>\n    </tr>\n    <tr>\n      <th>30-34</th>\n      <td>192</td>\n    </tr>\n    <tr>\n      <th>35-39</th>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>40-44</th>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>45-49</th>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>≥50</th>\n      <td>245</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_lengths = collections.Counter()\n",
    "for document in documents:\n",
    "    for qas in document.meta[\"qas\"]:\n",
    "        for answer in qas[\"answers\"]:\n",
    "            text = None\n",
    "            if answer[\"answer\"][\"unanswerable\"]:\n",
    "                text = \"Unanswerable\"\n",
    "            elif answer[\"answer\"][\"extractive_spans\"]:\n",
    "                text = \", \".join(answer[\"answer\"][\"extractive_spans\"])\n",
    "            elif answer[\"answer\"][\"free_form_answer\"]:\n",
    "                text = answer[\"answer\"][\"free_form_answer\"]\n",
    "            elif answer[\"answer\"][\"yes_no\"]:\n",
    "                text = \"Yes\"\n",
    "            elif answer[\"answer\"][\"yes_no\"] is not None:\n",
    "                text = \"No\"\n",
    "            answer_lengths[len(text.split())] += 1\n",
    "\n",
    "histogram(answer_lengths, 50, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer Types"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"free_form_answer\": 1931,\n",
      "    \"extractive_spans\": 4142,\n",
      "    \"yes_no\": 1110,\n",
      "    \"unanswerable\": 810\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_types = collections.Counter()\n",
    "for document in documents:\n",
    "    for qas in document.meta[\"qas\"]:\n",
    "        for answer in qas[\"answers\"]:\n",
    "            if answer[\"answer\"][\"unanswerable\"]:\n",
    "                answer_types[\"unanswerable\"] += 1\n",
    "            elif answer[\"answer\"][\"extractive_spans\"]:\n",
    "                answer_types[\"extractive_spans\"] += 1\n",
    "            elif answer[\"answer\"][\"free_form_answer\"]:\n",
    "                answer_types[\"free_form_answer\"] += 1\n",
    "            elif answer[\"answer\"][\"yes_no\"]:\n",
    "                answer_types[\"yes_no\"] += 1\n",
    "            elif answer[\"answer\"][\"yes_no\"] is not None:\n",
    "                answer_types[\"yes_no\"] += 1\n",
    "\n",
    "print(json.dumps(answer_types, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Most often-occurring questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   count                                          text\n0     36  Do they report results only on English data?\n1     18                    Which dataset do they use?\n2     14              What is the size of the dataset?\n3     13                        what was the baseline?\n4     12                        What was the baseline?\n5     12                       What datasets are used?\n6     12                       What are the baselines?\n7     10    Do they evaluate only on English datasets?\n8     10                     What dataset do they use?\n9     10                       what are the baselines?",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36</td>\n      <td>Do they report results only on English data?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>Which dataset do they use?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14</td>\n      <td>What is the size of the dataset?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13</td>\n      <td>what was the baseline?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>What was the baseline?</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12</td>\n      <td>What datasets are used?</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>12</td>\n      <td>What are the baselines?</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10</td>\n      <td>Do they evaluate only on English datasets?</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10</td>\n      <td>What dataset do they use?</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>what are the baselines?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter(qas[\"question\"] for document in documents for qas in document.meta[\"qas\"])\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"count\": [count for _, count in counter.most_common(10)],\n",
    "        \"text\": [text for text, _ in counter.most_common(10)],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Most often-occurring 'yes_no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   count   text\n0   6883   None\n1    611   True\n2    499  False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6883</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>611</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>499</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter(a[\"answer\"][\"yes_no\"] for document in documents for qas in document.meta[\"qas\"] for a in qas[\"answers\"])\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"count\": [count for _, count in counter.most_common(10)],\n",
    "        \"text\": [text for text, _ in counter.most_common(10)],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Most often-occurring 'free_form_answer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   count     text\n0   6062         \n1     15  English\n2      6        3\n3      4     None\n4      3        1\n5      3        2\n6      3       12\n7      3      SVM\n8      3        5\n9      2      one",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6062</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15</td>\n      <td>English</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>SVM</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>one</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter(a[\"answer\"][\"free_form_answer\"] for document in documents for qas in document.meta[\"qas\"] for a in qas[\"answers\"])\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"count\": [count for _, count in counter.most_common(10)],\n",
    "        \"text\": [text for text, _ in counter.most_common(10)],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Most often-occurring 'unanswerable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   count   text\n0   7183  False\n1    810   True",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7183</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>810</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter(a[\"answer\"][\"unanswerable\"] for document in documents for qas in document.meta[\"qas\"] for a in qas[\"answers\"])\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"count\": [count for _, count in counter.most_common(10)],\n",
    "        \"text\": [text for text, _ in counter.most_common(10)],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Most often-occurring 'extractive_spans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   count                                       text\n0   3851                                         ()\n1     23                                 (English,)\n2      9                                    (LSTM,)\n3      7                                 (Twitter,)\n4      7                  (Amazon Mechanical Turk,)\n5      6                                (accuracy,)\n6      6                                (English ,)\n7      5                                    (BERT,)\n8      4                                   (three,)\n9      4  (Peng and Dredze peng-dredze:2016:P16-2,)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3851</td>\n      <td>()</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23</td>\n      <td>(English,)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9</td>\n      <td>(LSTM,)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>(Twitter,)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>(Amazon Mechanical Turk,)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>(accuracy,)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>(English ,)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5</td>\n      <td>(BERT,)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4</td>\n      <td>(three,)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>(Peng and Dredze peng-dredze:2016:P16-2,)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter(tuple(a[\"answer\"][\"extractive_spans\"]) for document in documents for qas in document.meta[\"qas\"] for a in qas[\"answers\"])\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"count\": [count for _, count in counter.most_common(10)],\n",
    "        \"text\": [text for text, _ in counter.most_common(10)],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Number of evidence paragraphs per answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    # evidence paragraphs  # answers with this many evidence paragraphs\n2                       0                                          1023\n0                       1                                          4533\n1                       2                                          1332\n3                       3                                           420\n4                       4                                           253\n5                       5                                           140\n6                       6                                            85\n7                       7                                            57\n8                       8                                            49\n9                       9                                            36\n10                     10                                            15\n11                     11                                            14\n12                     12                                             8\n14                     13                                             4\n13                     14                                             6\n15                     15                                             4\n25                     16                                             1\n17                     18                                             2\n22                     19                                             1\n20                     20                                             1\n16                     21                                             2\n21                     23                                             1\n19                     24                                             2\n18                     37                                             2\n24                     41                                             1\n23                     52                                             1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># evidence paragraphs</th>\n      <th># answers with this many evidence paragraphs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1023</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>4533</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1332</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>420</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>253</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>140</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>13</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>19</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>21</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>23</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>24</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>37</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>41</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_evidence = collections.Counter()\n",
    "for document in documents:\n",
    "    for qas in document.meta[\"qas\"]:\n",
    "        for answer in qas[\"answers\"]:\n",
    "            num_evidence[len(answer[\"answer\"][\"evidence\"])] += 1\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"# evidence paragraphs\": [count for count, _  in num_evidence.most_common()],\n",
    "    \"# answers with this many evidence paragraphs\": [count for _, count in num_evidence.most_common()]\n",
    "}).sort_values(\"# evidence paragraphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Number of evidence nodes per evidence paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   # evidence nodes  # evidence paragraphs with this many evidence nodes\n1                 0                                                 53  \n0                 1                                              12678  \n2                 2                                                 20  \n3                 3                                                  6  \n4                 4                                                  3  \n5                 7                                                  1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># evidence nodes</th>\n      <th># evidence paragraphs with this many evidence nodes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>12678</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = collections.Counter()\n",
    "missed_evidence_paragraphs = collections.Counter()\n",
    "missing = []\n",
    "for document in documents:\n",
    "    for qas in document.meta[\"qas\"]:\n",
    "        for answer in qas[\"answers\"]:\n",
    "            counter = collections.Counter()\n",
    "            for node in document.nodes:\n",
    "                for is_evidence_for in node.meta[\"is_evidence_for\"]:\n",
    "                    if is_evidence_for[\"annotation_id\"] == answer[\"annotation_id\"]:\n",
    "                        counter[is_evidence_for[\"evidence_ix\"]] += 1\n",
    "            for ix in range(len(answer[\"answer\"][\"evidence\"])):\n",
    "                if counter[ix] == 0:\n",
    "                    missed_evidence_paragraphs[answer[\"answer\"][\"evidence\"][ix]] += 1\n",
    "                    missing.append((\n",
    "                        answer[\"answer\"][\"evidence\"][ix],\n",
    "                        [node.content for node in document.nodes],\n",
    "                        answer[\"annotation_id\"]\n",
    "                    ))\n",
    "                num_nodes[counter[ix]] += 1\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"# evidence nodes\": [count for count, _  in num_nodes.most_common()],\n",
    "    \"# evidence paragraphs with this many evidence nodes\": [count for _, count in num_nodes.most_common()]\n",
    "}).sort_values(\"# evidence nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Most often-occurring missing evidence paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    count                              missing evidence text\n0       4  $$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$ (...\n1       4  $$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{...\n2       3  $$ NST(\\tilde{E},N,K) = \\frac{1}{N \\vert \\tild...\n3       2  FLOAT SELECTED: Table 1: Average ROUGE-2 Score...\n4       2  $$freq(*, word) = freq(word, *) = freq(word)$$...\n5       1  FLOAT SELECTED: Table 2: Comparison of the pro...\n6       1  $$\\begin{split} g_t &= {\\rm sigmoid}(W_gx_t+b_...\n7       1  $$\\begin{split} o_t &= {\\rm BiLSTM}(o_{t-1}, [...\n8       1  $$\\begin{split} p_t &= {\\rm LSTM}(p_{t-1}, c_t...\n9       1  $${\\rm P}(\\textbf {a}|\\mathbf {O}) = \\prod _t ...\n10      1  $ f_r(h, t) & = & \\Vert \\textbf {W}_{r,1}\\text...\n11      1  FLOAT SELECTED: Table 2: Human evaluation on t...\n12      1  $$ \\begin{aligned} \\max _{f \\in \\mathcal {K}} ...\n13      1  Dynamic Memory stores information of entities ...\n14      1  FLOAT SELECTED: Fig. 1. Proposed representatio...\n15      1  $$h: \\hspace{14.22636pt} _1 &= _1, & _2 &= _2+...\n16      1  $$h: \\hspace{5.69046pt} _1 &= _1, & _2 &= _2 \\...\n17      1            $$g = \\sigma (e_c, e_w, e_s)$$ (Eq. 15)\n18      1  $$e = g \\odot (e_c, e_w, e_s) \\\\ h = \\text{LST...\n19      1  $$g = \\sigma (e_C, h) \\\\ \\hat{h} = g \\odot (e_...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>missing evidence text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>$$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$ (...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>$$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>$$ NST(\\tilde{E},N,K) = \\frac{1}{N \\vert \\tild...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>FLOAT SELECTED: Table 1: Average ROUGE-2 Score...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>$$freq(*, word) = freq(word, *) = freq(word)$$...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>FLOAT SELECTED: Table 2: Comparison of the pro...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>$$\\begin{split} g_t &amp;= {\\rm sigmoid}(W_gx_t+b_...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>$$\\begin{split} o_t &amp;= {\\rm BiLSTM}(o_{t-1}, [...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>$$\\begin{split} p_t &amp;= {\\rm LSTM}(p_{t-1}, c_t...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>$${\\rm P}(\\textbf {a}|\\mathbf {O}) = \\prod _t ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>$ f_r(h, t) &amp; = &amp; \\Vert \\textbf {W}_{r,1}\\text...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>FLOAT SELECTED: Table 2: Human evaluation on t...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>$$ \\begin{aligned} \\max _{f \\in \\mathcal {K}} ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>Dynamic Memory stores information of entities ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>FLOAT SELECTED: Fig. 1. Proposed representatio...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>$$h: \\hspace{14.22636pt} _1 &amp;= _1, &amp; _2 &amp;= _2+...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1</td>\n      <td>$$h: \\hspace{5.69046pt} _1 &amp;= _1, &amp; _2 &amp;= _2 \\...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1</td>\n      <td>$$g = \\sigma (e_c, e_w, e_s)$$ (Eq. 15)</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1</td>\n      <td>$$e = g \\odot (e_c, e_w, e_s) \\\\ h = \\text{LST...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1</td>\n      <td>$$g = \\sigma (e_C, h) \\\\ \\hat{h} = g \\odot (e_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"count\": [count for _, count in missed_evidence_paragraphs.most_common(20)],\n",
    "        \"missing evidence text\": [text for text, _ in missed_evidence_paragraphs.most_common(20)],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspection of missing evidence nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation ID: '1384b1e2ddc8d8417896cb3664c4586037474138'\n",
      "Evidence Paragraph: 'FLOAT SELECTED: Table 2: Comparison of the proposed ordinal regression neural network (ORNN) against Immediate-Threshold ordinal logistic regression (IT), All-Threshold ordinal logistic regression (AT), Least Absolute Deviation (LAD), multi-class logistic regression (MC), and the Human Trafficking Deep Network (HTDN) in terms of Mean Absolute Error (MAE), macro-averaged Mean Absolute Error (MAEM ), binary classification accuracy (Acc.) and weighted binary classification accuracy (Wt. Acc.). The results are averaged across 10-fold CV on Trafficking10k with naive standard errors in the parentheses. The best and second best results are highlighted.'\n",
      "- 'Table 2: Comparison of the proposed ordinal regression neural network (ORNN) against Immediate-Threshold ordinal logistic regression (IT), All-Threshold ordinal logistic regression (AT), Least Absolute Deviation (LAD), multi-class logistic regression (MC), and the Human Trafficking Deep Network (HTDN) in terms of Mean Absolute Error (MAE), macro-averaged Mean Absolute Error (MAEM ), binary classification accuracy (Acc.) and weighted binary classification accuracy (Wt. Acc.). The results are averaged across 10-fold CV on Trafficking10k with naive standard errors in the parentheses. The best and second best results are highlighted.'\n",
      "\n",
      "Annotation ID: '5370c482a9e9c424d28b8ecadac5f0bad4cc0b9e'\n",
      "Evidence Paragraph: '$$\\begin{split} g_t &= {\\rm sigmoid}(W_gx_t+b_g) \\\\ s_t &= {\\rm relu } (W_xx_t+b_x) \\\\ u_t &= g_t \\odot s_t + (1 - g_t) \\odot x_t~. \\end{split}$$ (Eq. 18)'\n",
      "- '$$\\begin{split}\n",
      "g_t &= {\\rm sigmoid}(W_gx_t+b_g) \\\\\n",
      "s_t &= {\\rm relu } (W_xx_t+b_x) \\\\\n",
      "u_t &= g_t \\odot s_t + (1 - g_t) \\odot x_t~.\n",
      "\\end{split}$$   (Eq. 18)'\n",
      "\n",
      "Annotation ID: '5370c482a9e9c424d28b8ecadac5f0bad4cc0b9e'\n",
      "Evidence Paragraph: '$$\\begin{split} o_t &= {\\rm BiLSTM}(o_{t-1}, [h_t, c_t]) \\\\ s_j^t &= w^T {\\rm tanh}(W_hh_j+\\tilde{W_h}h_t)\\\\ \\alpha _i^t &= {\\rm exp}(s_i^t)/\\Sigma _{j=1}^n{\\rm exp}(s_j^t)\\\\ c_t &= \\Sigma _{i=1}^n\\alpha _i^th_i ~. \\end{split}$$ (Eq. 20)'\n",
      "- '$$\\begin{split}\n",
      "o_t &= {\\rm BiLSTM}(o_{t-1}, [h_t, c_t]) \\\\\n",
      "s_j^t &= w^T {\\rm tanh}(W_hh_j+\\tilde{W_h}h_t)\\\\\n",
      "\\alpha _i^t &= {\\rm exp}(s_i^t)/\\Sigma _{j=1}^n{\\rm exp}(s_j^t)\\\\\n",
      "c_t &= \\Sigma _{i=1}^n\\alpha _i^th_i ~.\n",
      "\\end{split}$$   (Eq. 20)'\n",
      "\n",
      "Annotation ID: '5370c482a9e9c424d28b8ecadac5f0bad4cc0b9e'\n",
      "Evidence Paragraph: '$$\\begin{split} p_t &= {\\rm LSTM}(p_{t-1}, c_t) \\\\ s_j^t &= w^T {\\rm tanh}(W_oo_j+W_pp_{t-1})\\\\ \\beta _i^t &= {\\rm exp}(s_i^t)/\\Sigma _{j=1}^n{\\rm exp}(s_j^t)\\\\ c_t &= \\Sigma _{i=1}^n\\beta _i^to_i~. \\end{split}$$ (Eq. 21)'\n",
      "- '$$\\begin{split}\n",
      "p_t &= {\\rm LSTM}(p_{t-1}, c_t) \\\\\n",
      "s_j^t &= w^T {\\rm tanh}(W_oo_j+W_pp_{t-1})\\\\\n",
      "\\beta _i^t &= {\\rm exp}(s_i^t)/\\Sigma _{j=1}^n{\\rm exp}(s_j^t)\\\\\n",
      "c_t &= \\Sigma _{i=1}^n\\beta _i^to_i~.\n",
      "\\end{split}$$   (Eq. 21)'\n",
      "\n",
      "Annotation ID: '5370c482a9e9c424d28b8ecadac5f0bad4cc0b9e'\n",
      "Evidence Paragraph: '$${\\rm P}(\\textbf {a}|\\mathbf {O}) = \\prod _t {\\rm P}(a^t | a^1, ... , a^{t-1}, \\mathbf {O})~.$$ (Eq. 23)'\n",
      "- '$${\\rm P}(\\textbf {a}|\\mathbf {O}) = \\prod _t {\\rm P}(a^t | a^1, ... , a^{t-1}, \\mathbf {O})~.$$   (Eq. 23)'\n",
      "\n",
      "Annotation ID: '1c1dfad3a62e0b5a77ea7279312f43e2b0f155c0'\n",
      "Evidence Paragraph: '$ f_r(h, t) & = & \\Vert \\textbf {W}_{r,1}\\textbf {h} + \\textbf {r} - \\textbf {W}_{r,2}\\textbf {t}\\Vert _{\\ell _{1/2}} $'\n",
      "- '$\n",
      "f_r(h, t) & = & \\Vert  \\textbf {W}_{r,1}\\textbf {h} + \\textbf {r} - \\textbf {W}_{r,2}\\textbf {t}\\Vert _{\\ell _{1/2}}\n",
      "$'\n",
      "\n",
      "Annotation ID: 'f9429f69c0c10710e3d0f7a08e1402b4332774a0'\n",
      "Evidence Paragraph: 'FLOAT SELECTED: Table 2: Human evaluation on three aspects: relevance, attraction, and fluency. “None” represents the original headlines in the dataset.'\n",
      "- 'Table 2: Human evaluation on three aspects: relevance, attraction, and fluency. “None” represents the original headlines in the dataset.'\n",
      "\n",
      "Annotation ID: '38422bb256daf719d511514a73c66a26a115e80c'\n",
      "Evidence Paragraph: '$$ \\begin{aligned} \\max _{f \\in \\mathcal {K}} & \\; {unify}_(g, [f_{p}, f_{s}, f_{o}], (\\emptyset , )) \\\\ & = \\max _{f \\in \\mathcal {K}} \\; \\min \\big \\lbrace , \\operatorname{k}(_{\\scriptsize {grandpaOf}:}, _{f_{p}:}),\\\\ &\\qquad \\qquad \\qquad \\operatorname{k}(_{{abe}:}, _{f_{s}:}), \\operatorname{k}(_{{bart}:}, _{f_{o}:}) \\big \\rbrace , \\end{aligned}$$ (Eq. 3)'\n",
      "- '$$ \n",
      "\\begin{aligned}\n",
      "\\max _{f \\in \\mathcal {K}} & \\; {unify}_(g, [f_{p}, f_{s}, f_{o}], (\\emptyset , )) \\\\\n",
      "& = \\max _{f \\in \\mathcal {K}} \\; \\min \\big \\lbrace \n",
      ",\n",
      "\\operatorname{k}(_{\\scriptsize {grandpaOf}:}, _{f_{p}:}),\\\\\n",
      "&\\qquad \\qquad \\qquad \\operatorname{k}(_{{abe}:}, _{f_{s}:}),\n",
      "\\operatorname{k}(_{{bart}:}, _{f_{o}:})\n",
      "\\big \\rbrace ,\n",
      "\\end{aligned}$$   (Eq. 3)'\n",
      "\n",
      "Annotation ID: '474cd73f36a34ef605e6d33cb819097dade9dc5b'\n",
      "Evidence Paragraph: 'Dynamic Memory stores information of entities present in $T$ . This module is very similar to a Gated Recurrent Unit (GRU) BIBREF20 with a hidden state divided into blocks. Moreover, each block ideally represents an entity (i.e. person, location etc.), and it stores relevant facts about it. Each block $i$ is made of a hidden state $h_i\\in \\mathbb {R}^d$ and a key $k_i\\in \\mathbb {R}^d$ , where $d$ is the embedding size. The Dynamic Memory module is made of a set of blocks, which can be represent with a set of hidden states $\\lbrace h_1,\\dots ,h_z \\rbrace $ and their correspondent set of keys $\\lbrace k_1,\\dots ,k_z \\rbrace $ . The equation used to update a generic block $i$ are the following: $ g_i^{(t)} =& \\sigma (s_t^T h_i^{(t-1)} + s_t^T k_i^{(t-1)} + s_t^T q ) &\\text{(Gating Function)}&\\\\ \\hat{h}_i^{(t)} =& \\phi (U h_i^{(t-1)} + V k_i^{(t-1)} + W s_t ) &\\text{(Candidate Memory)}&\\\\ h_i^{(t)} =& h_i^{(t-1)} + g_i^{(t)} \\odot \\hat{h}_i^{(t)} &\\text{(New Memory)}&\\\\ h_i^{(t)} =& h_i^{(t)}/\\Vert h_i^{(t)} \\Vert &\\text{(Reset Memory)}&\\\\ $'\n",
      "- 'Dynamic Memory stores information of entities present in $T$ . This module is very similar to a Gated Recurrent Unit (GRU) BIBREF20 with a hidden state divided into blocks. Moreover, each block ideally represents an entity (i.e. person, location etc.), and it stores relevant facts about it. Each block $i$ is made of a hidden state $h_i\\in \\mathbb {R}^d$ and a key $k_i\\in \\mathbb {R}^d$ , where $d$ is the embedding size. The Dynamic Memory module is made of a set of blocks, which can be represent with a set of hidden states $\\lbrace  h_1,\\dots ,h_z \\rbrace $ and their correspondent set of keys $\\lbrace  k_1,\\dots ,k_z \\rbrace $ . The equation used to update a generic block $i$ are the following: $\n",
      "g_i^{(t)} =& \\sigma (s_t^T h_i^{(t-1)} + s_t^T k_i^{(t-1)} + s_t^T q ) &\\text{(Gating Function)}&\\\\\n",
      "\\hat{h}_i^{(t)} =& \\phi (U h_i^{(t-1)} + V k_i^{(t-1)} + W s_t ) &\\text{(Candidate Memory)}&\\\\\n",
      "h_i^{(t)} =& h_i^{(t-1)} + g_i^{(t)} \\odot \\hat{h}_i^{(t)} &\\text{(New Memory)}&\\\\\n",
      "h_i^{(t)} =& h_i^{(t)}/\\Vert  h_i^{(t)} \\Vert  &\\text{(Reset Memory)}&\\\\\n",
      "$'\n",
      "\n",
      "Annotation ID: '68de8331567cb04667b48a874d2c9c5c9084106c'\n",
      "Evidence Paragraph: 'FLOAT SELECTED: Fig. 1. Proposed representation learning method depicting the overall flow starting from a tweet to the learned features, including the architecture of the convolutional autoencoder.'\n",
      "- 'Fig. 1. Proposed representation learning method depicting the overall flow starting from a tweet to the learned features, including the architecture of the convolutional autoencoder.'\n",
      "\n",
      "Annotation ID: 'd81a91ef38c8fd6d74d7c9ef18cd79fb6d21ab30'\n",
      "Evidence Paragraph: '$$h: \\hspace{14.22636pt} _1 &= _1, & _2 &= _2+m(_1) \\nonumber \\\\ h^{-1}: \\hspace{14.22636pt} _1 &= _1, & _2 &= _2-m(_1) \\nonumber $$ (Eq. 15)'\n",
      "- '$$h: \\hspace{14.22636pt} _1 &= _1, & _2 &= _2+m(_1) \\nonumber \\\\\n",
      "h^{-1}: \\hspace{14.22636pt} _1 &= _1, & _2 &= _2-m(_1) \\nonumber $$   (Eq. 15)'\n",
      "- '$$h: \\hspace{5.69046pt} _1 &= _1, & _2 &= _2 \\odot \\text{exp}(s(_1)) + t(_1) \\nonumber \\\\\n",
      "h^{-1}: \\hspace{5.69046pt} _1 &= _1, & _2 &= (_2-t(_1)) \\odot \\text{exp}(-s(_1)) \\nonumber $$   (Eq. 16)'\n",
      "\n",
      "Annotation ID: 'd81a91ef38c8fd6d74d7c9ef18cd79fb6d21ab30'\n",
      "Evidence Paragraph: '$$h: \\hspace{5.69046pt} _1 &= _1, & _2 &= _2 \\odot \\text{exp}(s(_1)) + t(_1) \\nonumber \\\\ h^{-1}: \\hspace{5.69046pt} _1 &= _1, & _2 &= (_2-t(_1)) \\odot \\text{exp}(-s(_1)) \\nonumber $$ (Eq. 16)'\n",
      "- '$$h: \\hspace{5.69046pt} _1 &= _1, & _2 &= _2 \\odot \\text{exp}(s(_1)) + t(_1) \\nonumber \\\\\n",
      "h^{-1}: \\hspace{5.69046pt} _1 &= _1, & _2 &= (_2-t(_1)) \\odot \\text{exp}(-s(_1)) \\nonumber $$   (Eq. 16)'\n",
      "- '$$h: \\hspace{14.22636pt} _1 &= _1, & _2 &= _2+m(_1) \\nonumber \\\\\n",
      "h^{-1}: \\hspace{14.22636pt} _1 &= _1, & _2 &= _2-m(_1) \\nonumber $$   (Eq. 15)'\n",
      "\n",
      "Annotation ID: '95f7e191ce57a5695fd1a2155a895f1f37dbc631'\n",
      "Evidence Paragraph: '$$g = \\sigma (e_c, e_w, e_s)$$ (Eq. 15)'\n",
      "- '$$g = \\sigma (e_c, e_w, e_s)$$   (Eq. 15)'\n",
      "- '$$e = g \\odot (e_c, e_w, e_s) \\\\\n",
      "h = \\text{LSTM}(e)$$   (Eq. 16)'\n",
      "\n",
      "Annotation ID: '95f7e191ce57a5695fd1a2155a895f1f37dbc631'\n",
      "Evidence Paragraph: '$$e = g \\odot (e_c, e_w, e_s) \\\\ h = \\text{LSTM}(e)$$ (Eq. 16)'\n",
      "- '$$e = g \\odot (e_c, e_w, e_s) \\\\\n",
      "h = \\text{LSTM}(e)$$   (Eq. 16)'\n",
      "- '$$g = \\sigma (e_c, e_w, e_s)$$   (Eq. 15)'\n",
      "\n",
      "Annotation ID: '95f7e191ce57a5695fd1a2155a895f1f37dbc631'\n",
      "Evidence Paragraph: '$$g = \\sigma (e_C, h) \\\\ \\hat{h} = g \\odot (e_c, h)$$ (Eq. 17)'\n",
      "- '$$g = \\sigma (e_C, h) \\\\\n",
      "\\hat{h} = g \\odot (e_c, h)$$   (Eq. 17)'\n",
      "\n",
      "Annotation ID: 'c9e859ba02a47030b30a5a3623d17e1fbec90c8f'\n",
      "Evidence Paragraph: '$$P(q, a) = P(a) P(q|a) = P(q)P(a|q)$$ (Eq. 1)'\n",
      "- '$$P(q, a) = P(a) P(q|a) = P(q)P(a|q)$$   (Eq. 1)'\n",
      "- '$$P_a(a) P(q|a;\\theta _{qg}) = P_q(q)P(a|q;\\theta _{qa})$$   (Eq. 3)'\n",
      "\n",
      "Annotation ID: 'c9e859ba02a47030b30a5a3623d17e1fbec90c8f'\n",
      "Evidence Paragraph: '$$P_a(a) P(q|a;\\theta _{qg}) = P_q(q)P(a|q;\\theta _{qa})$$ (Eq. 3)'\n",
      "- '$$P_a(a) P(q|a;\\theta _{qg}) = P_q(q)P(a|q;\\theta _{qa})$$   (Eq. 3)'\n",
      "- '$$P(q, a) = P(a) P(q|a) = P(q)P(a|q)$$   (Eq. 1)'\n",
      "\n",
      "Annotation ID: 'c9e859ba02a47030b30a5a3623d17e1fbec90c8f'\n",
      "Evidence Paragraph: '$$l_{qg}(q, a) = -log P_{qg}(q|a;\\theta _{qg})$$ (Eq. 6)'\n",
      "- '$$l_{qg}(q, a) = -log P_{qg}(q|a;\\theta _{qg})$$   (Eq. 6)'\n",
      "\n",
      "Annotation ID: 'c9e859ba02a47030b30a5a3623d17e1fbec90c8f'\n",
      "Evidence Paragraph: '$$ \\nonumber l_{dual}(a,q;\\theta _{qa}, \\theta _{qg}) &= [logP_a(a) + log P(q|a;\\theta _{qg}) \\\\ & - logP_q(q) - logP(a|q;\\theta _{qa})]^2$$ (Eq. 9)'\n",
      "- '$$ \\nonumber l_{dual}(a,q;\\theta _{qa}, \\theta _{qg}) &= [logP_a(a) + log P(q|a;\\theta _{qg}) \\\\\n",
      "& - logP_q(q) - logP(a|q;\\theta _{qa})]^2$$   (Eq. 9)'\n",
      "\n",
      "Annotation ID: 'eac9f64711e043e0c4b25f86af56a2b3b0ada7fe'\n",
      "Evidence Paragraph: '$$\\begin{split} \\mathcal {J}_{\\text{SEQ-PIT}}=\\sum _u \\min _{s^{\\prime }\\in \\mathbf {S}} \\frac{1}{N} \\sum _{n\\in [1,N]}-\\mathcal {J}_{\\text{SEQ}}(\\mathbf {L}_{un}^{(s^{\\prime })},\\mathbf {L}_{un}^{(r)}) \\end{split}$$ (Eq. 44)'\n",
      "- '$$\\begin{split}\n",
      "\\mathcal {J}_{\\text{SEQ-PIT}}=\\sum _u \\min _{s^{\\prime }\\in \\mathbf {S}} \\frac{1}{N} \\sum _{n\\in [1,N]}-\\mathcal {J}_{\\text{SEQ}}(\\mathbf {L}_{un}^{(s^{\\prime })},\\mathbf {L}_{un}^{(r)})\n",
      "\\end{split}$$   (Eq. 44)'\n",
      "- '$$\\begin{split}\n",
      "\\mathcal {J}_{\\text{CE-PIT}}=\\sum _u \\min _{s^{\\prime }\\in \\mathbf {S}} \\sum _t \\frac{1}{N} \\sum _{n\\in [1,N]} CE({l}_{utn}^{(s^{\\prime })},{l}_{utn}^{(r)})\n",
      "\\end{split}$$   (Eq. 7)'\n",
      "- '$$\\begin{split}\n",
      "\\mathcal {J}_{\\text{U-PIT}}=\\sum _u \\min _{s^{\\prime }\\in \\mathbf {S}} \\sum _t \\frac{1}{N} \\sum _{n\\in [1,N]} MSE({o}_{utn}^{(s^{\\prime })},{o}_{utn}^{(r)})\n",
      "\\end{split}$$   (Eq. 13)'\n",
      "\n",
      "Annotation ID: 'aa9090778e7bae7a43558276d8344e0547ed809d'\n",
      "Evidence Paragraph: 'We compare two types of subwords: simple n-grams (like fastText) and unsupervised morphemes. For example, given the word “cat”, we mark beginning and end with angled brackets and use all n-grams of length 3 to 6 as subwords, yielding $S_{\\textnormal {cat}} = \\lbrace \\textnormal {$ $ ca, at$ $, cat} \\rbrace $ . Morfessor BIBREF11 is used to probabilistically segment words into morphemes. The Morfessor model is trained using raw text so it is entirely unsupervised. For the word “subsequent”, we get $S_{\\textnormal {subsequent}} = \\lbrace \\textnormal {$ $ sub, sequent$ $} \\rbrace $ .'\n",
      "- 'We compare two types of subwords: simple n-grams (like fastText) and unsupervised morphemes. For example, given the word “cat”, we mark beginning and end with angled brackets and use all n-grams of length 3 to 6 as subwords, yielding $S_{\\textnormal {cat}} = \\lbrace  \\textnormal {$ $ ca, at$ $, cat} \\rbrace $ . Morfessor BIBREF11 is used to probabilistically segment words into morphemes. The Morfessor model is trained using raw text so it is entirely unsupervised. For the word “subsequent”, we get $S_{\\textnormal {subsequent}} = \\lbrace  \\textnormal {$ $ sub, sequent$ $} \\rbrace $ .'\n",
      "\n",
      "Annotation ID: '7eecbe1aed7f283bdd4ca6c207115dbfca91d57d'\n",
      "Evidence Paragraph: '$$L_{model} = \\hat{L}_{dec} + \\hat{L}_{refine}$$ (Eq. 23)'\n",
      "- '$$L_{model} = \\hat{L}_{dec} + \\hat{L}_{refine}$$   (Eq. 23)'\n",
      "\n",
      "Annotation ID: '5103743e0b630c27ab4f9edb52bad084202bd16f'\n",
      "Evidence Paragraph: '$$\\begin{aligned} &\\mathcal {L}_{se}(\\mathbf {v}^1_\\ast , \\mathcal {C}_\\ast ^1) = -\\log p(\\mathcal {C}_\\ast ^1 | \\mathbf {v}^1_\\ast ) \\\\ & = - \\sum _{c \\in \\mathcal {C}_\\ast ^1}\\log p(c_\\ast ^1 | \\mathbf {v}^1_\\ast ) + \\sum _{c \\in \\mathcal {C}_\\ast \\setminus \\mathcal {C}_\\ast ^1}\\log p(c_\\ast ^1 | \\mathbf {v}^1_\\ast ) \\end{aligned}$$ (Eq. 19)'\n",
      "- '$$\\begin{aligned}\n",
      "&\\mathcal {L}_{se}(\\mathbf {v}^1_\\ast , \\mathcal {C}_\\ast ^1) = -\\log p(\\mathcal {C}_\\ast ^1 | \\mathbf {v}^1_\\ast ) \\\\\n",
      "& = - \\sum _{c \\in \\mathcal {C}_\\ast ^1}\\log p(c_\\ast ^1 | \\mathbf {v}^1_\\ast ) + \\sum _{c \\in \\mathcal {C}_\\ast \\setminus \\mathcal {C}_\\ast ^1}\\log p(c_\\ast ^1 | \\mathbf {v}^1_\\ast )\n",
      "\\end{aligned}$$   (Eq. 19)'\n",
      "\n",
      "Annotation ID: '5103743e0b630c27ab4f9edb52bad084202bd16f'\n",
      "Evidence Paragraph: '$$\\begin{aligned} \\mathcal {L}_{du} = -\\log p(\\mathcal {C}_d^1 | \\mathbf {v}_m^1) - \\log p(\\mathcal {C}_m^1 | \\mathbf {v}_d^1) \\end{aligned}$$ (Eq. 20)'\n",
      "- '$$\\begin{aligned}\n",
      "\\mathcal {L}_{du} = -\\log p(\\mathcal {C}_d^1 | \\mathbf {v}_m^1) - \\log p(\\mathcal {C}_m^1 | \\mathbf {v}_d^1)\n",
      "\\end{aligned}$$   (Eq. 20)'\n",
      "\n",
      "Annotation ID: '9931b14a7d8e4a3e419718327c233ab7fb8fdb34'\n",
      "Evidence Paragraph: 'where $x$ is the subcategory and $y$ is the supercategory. This means the general concept embedding should be smaller than the specific concept embedding in every coordinate of the embeddings. An illustration of this geometry can be found in Figure 1. We can define a surrogate energy for this ordering function as $d(x, y) = \\left\\Vert \\max (0,y-x) \\right\\Vert ^2$ . The learning objective for order embeddings becomes the following, where $m$ is a margin parameter, $x$ and $y$ are the hierarchically supervised pairs, and $x^{\\prime }$ and $y^{\\prime }$ are negatively sampled concepts: $ L_{\\text{Order}} = \\sum _{x,y}\\max (0, m+d(x,y)-d(x^{\\prime }, y^{\\prime })) $'\n",
      "- 'where $x$ is the subcategory and $y$ is the supercategory. This means the general concept embedding should be smaller than the specific concept embedding in every coordinate of the embeddings. An illustration of this geometry can be found in Figure 1. We can define a surrogate energy for this ordering function as $d(x, y) = \\left\\Vert  \\max (0,y-x) \\right\\Vert ^2$ . The learning objective for order embeddings becomes the following, where $m$ is a margin parameter, $x$ and $y$ are the hierarchically supervised pairs, and $x^{\\prime }$ and $y^{\\prime }$ are negatively sampled concepts: $\n",
      "L_{\\text{Order}} = \\sum _{x,y}\\max (0, m+d(x,y)-d(x^{\\prime }, y^{\\prime }))\n",
      "$'\n",
      "\n",
      "Annotation ID: 'd2dacf31ba045f35ca309853cd3e30f975fce358'\n",
      "Evidence Paragraph: '$$\\log \\sigma (w \\cdot c) + \\sum _{i = 1}^{k} \\mathbb {E}_{\\tilde{c}_i \\sim P(w)} [\\log \\sigma (-w \\cdot \\tilde{c}_i)]$$ (Eq. 7)'\n",
      "- '$$\\log \\sigma (w \\cdot c) + \\sum _{i = 1}^{k} \\mathbb {E}_{\\tilde{c}_i \\sim P(w)} [\\log \\sigma (-w \\cdot \\tilde{c}_i)]$$   (Eq. 7)'\n",
      "- '$$\\log \\sigma (f(w) \\cdot c) + \\sum _{i = 1}^{k} \\mathbb {E}_{\\tilde{c}_i \\sim P(w)} [\\log \\sigma (-f(w) \\cdot \\tilde{c}_i)]$$   (Eq. 8)'\n",
      "\n",
      "Annotation ID: 'd2dacf31ba045f35ca309853cd3e30f975fce358'\n",
      "Evidence Paragraph: '$$\\log \\sigma (f(w) \\cdot c) + \\sum _{i = 1}^{k} \\mathbb {E}_{\\tilde{c}_i \\sim P(w)} [\\log \\sigma (-f(w) \\cdot \\tilde{c}_i)]$$ (Eq. 8)'\n",
      "- '$$\\log \\sigma (f(w) \\cdot c) + \\sum _{i = 1}^{k} \\mathbb {E}_{\\tilde{c}_i \\sim P(w)} [\\log \\sigma (-f(w) \\cdot \\tilde{c}_i)]$$   (Eq. 8)'\n",
      "- '$$\\log \\sigma (w \\cdot c) + \\sum _{i = 1}^{k} \\mathbb {E}_{\\tilde{c}_i \\sim P(w)} [\\log \\sigma (-w \\cdot \\tilde{c}_i)]$$   (Eq. 7)'\n",
      "\n",
      "Annotation ID: 'd2dacf31ba045f35ca309853cd3e30f975fce358'\n",
      "Evidence Paragraph: '$$a(h_i) = \\frac{\\exp (v^{T} \\tanh (Wh_i))}{\\sum _j \\exp (v^{T} \\tanh (Wh_j))}$$ (Eq. 10)'\n",
      "- '$$a(h_i) = \\frac{\\exp (v^{T} \\tanh (Wh_i))}{\\sum _j \\exp (v^{T} \\tanh (Wh_j))}$$   (Eq. 10)'\n",
      "\n",
      "Annotation ID: 'd2dacf31ba045f35ca309853cd3e30f975fce358'\n",
      "Evidence Paragraph: '$$w = \\operatornamewithlimits{argmax}_{w \\in V - \\lbrace a, b, c\\rbrace } \\cos (w, b - a + c)$$ (Eq. 28)'\n",
      "- '$$w = \\operatornamewithlimits{argmax}_{w \\in V - \\lbrace a, b, c\\rbrace } \\cos (w, b - a + c)$$   (Eq. 28)'\n",
      "\n",
      "Annotation ID: '2a1b8f1fc516070fefc7257dce0079e8ade29a0b'\n",
      "Evidence Paragraph: '$$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$ (Eq. 7)'\n",
      "- '$$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$   (Eq. 7)'\n",
      "\n",
      "Annotation ID: '2a1b8f1fc516070fefc7257dce0079e8ade29a0b'\n",
      "Evidence Paragraph: '$$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{\\textsc {Len}(q)}$$ (Eq. 8)'\n",
      "- '$$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{\\textsc {Len}(q)}$$   (Eq. 8)'\n",
      "\n",
      "Annotation ID: '2c3e7d6057ace540d12d9294375a86f8dfe90f98'\n",
      "Evidence Paragraph: '$$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$ (Eq. 7)'\n",
      "- '$$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$   (Eq. 7)'\n",
      "\n",
      "Annotation ID: '2c3e7d6057ace540d12d9294375a86f8dfe90f98'\n",
      "Evidence Paragraph: '$$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{\\textsc {Len}(q)}$$ (Eq. 8)'\n",
      "- '$$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{\\textsc {Len}(q)}$$   (Eq. 8)'\n",
      "\n",
      "Annotation ID: 'ce590983744bc62a69b9ab15c5363a2a936ab915'\n",
      "Evidence Paragraph: '$$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$ (Eq. 7)'\n",
      "- '$$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$   (Eq. 7)'\n",
      "\n",
      "Annotation ID: 'd6e43d49b397b5e2109300fbfc1f7c6f74c8665f'\n",
      "Evidence Paragraph: '$$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$ (Eq. 7)'\n",
      "- '$$\\textsc {Rel}(q) = \\cos (v(q),v(D_{in}))$$   (Eq. 7)'\n",
      "\n",
      "Annotation ID: '2ba04269643a704586187b26b60e40bbb1d9b294'\n",
      "Evidence Paragraph: '$$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{\\textsc {Len}(q)}$$ (Eq. 8)'\n",
      "- '$$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{\\textsc {Len}(q)}$$   (Eq. 8)'\n",
      "\n",
      "Annotation ID: '3571015101664176ed817f4e72023379a0022518'\n",
      "Evidence Paragraph: '$$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{\\textsc {Len}(q)}$$ (Eq. 8)'\n",
      "- '$$\\textsc {AvgLM}(q) = \\frac{\\textsc {Lm}(q)}{\\textsc {Len}(q)}$$   (Eq. 8)'\n",
      "\n",
      "Annotation ID: '7cf2955d35c98da45ca6a8ec89940d6b759ff772'\n",
      "Evidence Paragraph: 'FLOAT SELECTED: Table 1: Average ROUGE-2 Scores for Different Combination of Models.'\n",
      "- 'Table 1: Average ROUGE-2 Scores for Different Combination of Models.'\n",
      "- 'Table 2: Average ROUGE-2 scores for base methods.'\n",
      "\n",
      "Annotation ID: '7cf2955d35c98da45ca6a8ec89940d6b759ff772'\n",
      "Evidence Paragraph: 'FLOAT SELECTED: Table 1: Average ROUGE-2 Scores for Different Combination of Models.'\n",
      "- 'Table 1: Average ROUGE-2 Scores for Different Combination of Models.'\n",
      "- 'Table 2: Average ROUGE-2 scores for base methods.'\n",
      "\n",
      "Annotation ID: '3641cbf2a8b90c1053aaefb7db23ef501bffa196'\n",
      "Evidence Paragraph: '$$ NST(\\tilde{E},N,K) = \\frac{1}{N \\vert \\tilde{E} \\vert } \\sum _{e \\in \\tilde{E}} \\sum _{j=1}^N \\frac{\\vert C_K(e) \\cap C_K(n_j^{(e)}) \\vert }{\\vert C_K(e) \\cup C_K(n_j^{(e)}) \\vert }$$ (Eq. 19)'\n",
      "- '$$ \n",
      "NST(\\tilde{E},N,K) = \\frac{1}{N \\vert \\tilde{E} \\vert } \\sum _{e \\in \\tilde{E}} \\sum _{j=1}^N \\frac{\\vert C_K(e) \\cap C_K(n_j^{(e)}) \\vert }{\\vert C_K(e) \\cup C_K(n_j^{(e)}) \\vert }$$   (Eq. 19)'\n",
      "\n",
      "Annotation ID: '8132433c110b826230941f9be14befd651ba9f81'\n",
      "Evidence Paragraph: '$$ NST(\\tilde{E},N,K) = \\frac{1}{N \\vert \\tilde{E} \\vert } \\sum _{e \\in \\tilde{E}} \\sum _{j=1}^N \\frac{\\vert C_K(e) \\cap C_K(n_j^{(e)}) \\vert }{\\vert C_K(e) \\cup C_K(n_j^{(e)}) \\vert }$$ (Eq. 19)'\n",
      "- '$$ \n",
      "NST(\\tilde{E},N,K) = \\frac{1}{N \\vert \\tilde{E} \\vert } \\sum _{e \\in \\tilde{E}} \\sum _{j=1}^N \\frac{\\vert C_K(e) \\cap C_K(n_j^{(e)}) \\vert }{\\vert C_K(e) \\cup C_K(n_j^{(e)}) \\vert }$$   (Eq. 19)'\n",
      "\n",
      "Annotation ID: 'cc29159cae181a8f86e2afae6bcd31ad40e84a67'\n",
      "Evidence Paragraph: '$$ NST(\\tilde{E},N,K) = \\frac{1}{N \\vert \\tilde{E} \\vert } \\sum _{e \\in \\tilde{E}} \\sum _{j=1}^N \\frac{\\vert C_K(e) \\cap C_K(n_j^{(e)}) \\vert }{\\vert C_K(e) \\cup C_K(n_j^{(e)}) \\vert }$$ (Eq. 19)'\n",
      "- '$$ \n",
      "NST(\\tilde{E},N,K) = \\frac{1}{N \\vert \\tilde{E} \\vert } \\sum _{e \\in \\tilde{E}} \\sum _{j=1}^N \\frac{\\vert C_K(e) \\cap C_K(n_j^{(e)}) \\vert }{\\vert C_K(e) \\cup C_K(n_j^{(e)}) \\vert }$$   (Eq. 19)'\n",
      "\n",
      "Annotation ID: '9b10ee1728505009a569cbc5eed3eaefb9b9ea1e'\n",
      "Evidence Paragraph: '$$\\frac{1}{3} \\sum _{u \\in T} \\sum _{u^{\\prime } \\in T \\setminus u} \\log p(u | u^{\\prime })$$ (Eq. 9)'\n",
      "- '$$\\frac{1}{3} \\sum _{u \\in T} \\sum _{u^{\\prime } \\in T \\setminus u} \\log p(u | u^{\\prime })$$   (Eq. 9)'\n",
      "\n",
      "Annotation ID: 'c73376b68ac9b57347557921e25a1831a7f79fa9'\n",
      "Evidence Paragraph: '$$\\begin{aligned} & Y_1=g( f_{LM}( M_i ) ), Y_2=g( T_i ) \\\\ & measure = Cross~Entropy(Y_1, Y_2), \\\\ \\end{aligned}$$ (Eq. 11)'\n",
      "- '$$\\begin{aligned}\n",
      "& Y_1=g( f_{LM}( M_i ) ), Y_2=g( T_i ) \\\\\n",
      "& measure = Cross~Entropy(Y_1, Y_2), \\\\\n",
      "\\end{aligned}$$   (Eq. 11)'\n",
      "\n",
      "Annotation ID: '1bbefe218d9e505c1b7d369ad4e275d307eb6cd3'\n",
      "Evidence Paragraph: 'FLOAT SELECTED: Table 2. Left: Performance of our AEG model on IMDB and AG’s News dataset using word and character based CNN models respectively. Results indicate the percentage dip in the accuracy by using the corresponding attacking model over the original accuracy. Right: Performance of different variants of our model.'\n",
      "- 'Table 2. Left: Performance of our AEG model on IMDB and AG’s News dataset using word and character based CNN models respectively. Results indicate the percentage dip in the accuracy by using the corresponding attacking model over the original accuracy. Right: Performance of different variants of our model.'\n",
      "\n",
      "Annotation ID: '59be594c1974a2f8025cbdef2481c4bb605e5103'\n",
      "Evidence Paragraph: '$$s_{i,j} = \\sum _{k \\in \\Gamma (i) \\cap \\Gamma (j)} \\frac{1}{\\log \\left( \\#| \\Gamma (k)|\\right)},$$ (Eq. 28)'\n",
      "- '$$s_{i,j} = \\sum _{k \\in \\Gamma (i) \\cap \\Gamma (j)} \\frac{1}{\\log \\left(\n",
      "\\#| \\Gamma (k)|\\right)},$$   (Eq. 28)'\n",
      "\n",
      "Annotation ID: '63420066e09ba1e8cbb4523b9d8e94856b6bf5f6'\n",
      "Evidence Paragraph: '$$z_i = \\sum _{j=1}^{n} \\alpha _{ij} (x_jW^V)$$ (Eq. 3)'\n",
      "- '$$z_i = \\sum _{j=1}^{n} \\alpha _{ij} (x_jW^V)$$   (Eq. 3)'\n",
      "- '$$z_i = \\sum _{j=1}^{n} \\alpha _{ij} (x_jW^V + a^V_{ij})$$   (Eq. 6)'\n",
      "\n",
      "Annotation ID: '63420066e09ba1e8cbb4523b9d8e94856b6bf5f6'\n",
      "Evidence Paragraph: '$$e_{ij} = \\frac{(x_iW^Q)(x_jW^K)^T}{\\sqrt{d_z}}$$ (Eq. 4)'\n",
      "- '$$e_{ij} = \\frac{(x_iW^Q)(x_jW^K)^T}{\\sqrt{d_z}}$$   (Eq. 4)'\n",
      "- '$$e_{ij} = \\frac{x_iW^Q(x_jW^K+a^K_{ij})^T}{\\sqrt{d_z}}$$   (Eq. 7)'\n",
      "- '$$e_{ij} = \\frac{x_iW^Q(x_jW^K)^T + x_iW^Q(a^K_{ij})^T}{\\sqrt{d_z}}$$   (Eq. 11)'\n",
      "\n",
      "Annotation ID: '63420066e09ba1e8cbb4523b9d8e94856b6bf5f6'\n",
      "Evidence Paragraph: '$$z_i = \\sum _{j=1}^{n} \\alpha _{ij} (x_jW^V + a^V_{ij})$$ (Eq. 6)'\n",
      "- '$$z_i = \\sum _{j=1}^{n} \\alpha _{ij} (x_jW^V + a^V_{ij})$$   (Eq. 6)'\n",
      "- '$$z_i = \\sum _{j=1}^{n} \\alpha _{ij} (x_jW^V)$$   (Eq. 3)'\n",
      "\n",
      "Annotation ID: '63420066e09ba1e8cbb4523b9d8e94856b6bf5f6'\n",
      "Evidence Paragraph: '$$e_{ij} = \\frac{x_iW^Q(x_jW^K+a^K_{ij})^T}{\\sqrt{d_z}}$$ (Eq. 7)'\n",
      "- '$$e_{ij} = \\frac{x_iW^Q(x_jW^K+a^K_{ij})^T}{\\sqrt{d_z}}$$   (Eq. 7)'\n",
      "- '$$e_{ij} = \\frac{x_iW^Q(x_jW^K)^T + x_iW^Q(a^K_{ij})^T}{\\sqrt{d_z}}$$   (Eq. 11)'\n",
      "- '$$e_{ij} = \\frac{(x_iW^Q)(x_jW^K)^T}{\\sqrt{d_z}}$$   (Eq. 4)'\n",
      "\n",
      "Annotation ID: '7c6130366dfa70e9b39f0ecc5ef3c52a8b81a928'\n",
      "Evidence Paragraph: '$$freq(*, word) = freq(word, *) = freq(word)$$ (Eq. 1)'\n",
      "- '$$freq(*, word) = freq(word, *) = freq(word)$$   (Eq. 1)'\n",
      "\n",
      "Annotation ID: 'bcab7640269f1114852d7b276610239018a17556'\n",
      "Evidence Paragraph: '$$freq(*, word) = freq(word, *) = freq(word)$$ (Eq. 1)'\n",
      "- '$$freq(*, word) = freq(word, *) = freq(word)$$   (Eq. 1)'\n",
      "\n",
      "Annotation ID: '85e018a2f8eda0574d99118db2b3b70c26d26750'\n",
      "Evidence Paragraph: '$$p_1 &=& f\\left( \\begin{bmatrix} x_1 & x_2 \\end{bmatrix} W_{tsr}^{[1:d]} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} + \\begin{bmatrix} x_1 & x_2 \\end{bmatrix} W + b \\right) \\\\ p_2 &=& f\\left( \\begin{bmatrix} p_1 & x_3 \\end{bmatrix} W_{tsr}^{[1:d]} \\begin{bmatrix} p_1 \\\\ x_3 \\end{bmatrix} + \\begin{bmatrix} p_1 & x_3 \\end{bmatrix} W + b \\right)$$ (Eq. 15)'\n",
      "- '$$p_1 &=& f\\left(\n",
      "\\begin{bmatrix} x_1 & x_2 \\end{bmatrix} W_{tsr}^{[1:d]} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} + \\begin{bmatrix} x_1 & x_2 \\end{bmatrix} W + b \\right) \\\\\n",
      "p_2 &=& f\\left(\n",
      "\\begin{bmatrix} p_1 & x_3 \\end{bmatrix} W_{tsr}^{[1:d]} \\begin{bmatrix} p_1 \\\\ x_3 \\end{bmatrix} + \\begin{bmatrix} p_1 & x_3 \\end{bmatrix} W + b \\right)$$   (Eq. 15)'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for evidence_paragraph, node_contents, annotation_id in missing:\n",
    "    print(f\"Annotation ID: '{annotation_id}'\")\n",
    "    print(f\"Evidence Paragraph: '{evidence_paragraph}'\")\n",
    "    for node_content in difflib.get_close_matches(evidence_paragraph, node_contents):\n",
    "        print(f\"- '{node_content}'\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Title Patterns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    count\n# titles that contain ':::'          6946\n# titles that do not contain ':::'  14963",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th># titles that contain ':::'</th>\n      <td>6946</td>\n    </tr>\n    <tr>\n      <th># titles that do not contain ':::'</th>\n      <td>14963</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes, no = 0, 0\n",
    "for document in documents:\n",
    "    for node in document.nodes:\n",
    "        if node.ntype == \"title\":\n",
    "            if \":::\" in node.content:\n",
    "                yes += 1\n",
    "            else:\n",
    "                no += 1\n",
    "pd.DataFrame(\n",
    "    index=[\"# titles that contain ':::'\", \"# titles that do not contain ':::'\"],\n",
    "    data={\n",
    "        \"count\": [yes, no]\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Most often-occurring titles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   count                        text\n0   1499                Introduction\n1    818                  Conclusion\n2    626                Related Work\n3    376             Acknowledgments\n4    332                 Experiments\n5    305                     Results\n6    252                 Conclusions\n7    212            Acknowledgements\n8    165                  Discussion\n9    139  Conclusion and Future Work",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1499</td>\n      <td>Introduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>818</td>\n      <td>Conclusion</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>626</td>\n      <td>Related Work</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>376</td>\n      <td>Acknowledgments</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>332</td>\n      <td>Experiments</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>305</td>\n      <td>Results</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>252</td>\n      <td>Conclusions</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>212</td>\n      <td>Acknowledgements</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>165</td>\n      <td>Discussion</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>139</td>\n      <td>Conclusion and Future Work</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter(node.content for document in documents for node in document.nodes if node.ntype == \"title\")\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"count\": [count for _, count in counter.most_common(10)],\n",
    "        \"text\": [text for text, _ in counter.most_common(10)],\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}