{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "from intertext_graph.itgraph import IntertextDocument\n",
    "\n",
    "import config\n",
    "from histogram import histogram\n",
    "from metadata_analyzer import parse_json_object\n",
    "\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l) / len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evidence Inference Metadata Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The value of \"path.EVIDENCE-INFERENCE-ITG\" cannot be changed after it has been accessed!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# configuration\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_config_json_file\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../path_config_local.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_in_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Source\\MA\\ma-venv\\lib\\site-packages\\repliconfig\\config.py:153\u001B[0m, in \u001B[0;36mload_config_json_file\u001B[1;34m(file_path, forced, include_in_hash)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m    152\u001B[0m     config \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(file)\n\u001B[1;32m--> 153\u001B[0m \u001B[43mload_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforced\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_in_hash\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Source\\MA\\ma-venv\\lib\\site-packages\\repliconfig\\config.py:109\u001B[0m, in \u001B[0;36mload_config\u001B[1;34m(config, forced, include_in_hash)\u001B[0m\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe include_in_hash parameter value \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minclude_in_hash\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is not a bool!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m identifier, value \u001B[38;5;129;01min\u001B[39;00m config\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m--> 109\u001B[0m     \u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43midentifier\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforced\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_in_hash\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Source\\MA\\ma-venv\\lib\\site-packages\\repliconfig\\config.py:73\u001B[0m, in \u001B[0;36mset\u001B[1;34m(identifier, value, forced, include_in_hash)\u001B[0m\n\u001B[0;32m     70\u001B[0m old_value, old_forced, old_include_in_hash, old_accessed \u001B[38;5;241m=\u001B[39m _store[identifier]\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m old_accessed:\n\u001B[1;32m---> 73\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe value of \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00midentifier\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m cannot be changed after it has been accessed!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m old_forced \u001B[38;5;129;01mand\u001B[39;00m forced:\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe new value of \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00midentifier\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m cannot be forced since the old value has already\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     77\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbeen forced!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: The value of \"path.EVIDENCE-INFERENCE-ITG\" cannot be changed after it has been accessed!"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "config.load_config_json_file(\"../path_config_local.json\", include_in_hash=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4454 documents.\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "documents = []\n",
    "path = os.path.join(config.get(\"path.EVIDENCE-INFERENCE-ITG\"), \"deep-train.jsonl\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for document_json_str in file:\n",
    "        with StringIO(document_json_str) as f:\n",
    "            document = IntertextDocument.load_json(f)\n",
    "            documents.append(document)\n",
    "path = os.path.join(config.get(\"path.EVIDENCE-INFERENCE-ITG\"), \"deep-dev.jsonl\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for document_json_str in file:\n",
    "        with StringIO(document_json_str) as f:\n",
    "            document = IntertextDocument.load_json(f)\n",
    "            documents.append(document)\n",
    "path = os.path.join(config.get(\"path.EVIDENCE-INFERENCE-ITG\"), \"deep-test.jsonl\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for document_json_str in file:\n",
    "        with StringIO(document_json_str) as f:\n",
    "            document = IntertextDocument.load_json(f)\n",
    "            documents.append(document)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Document Metadata Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/1x [\n",
      "      4454/4454x {\n",
      "        'pmc_id': 4454/4454x non-empty string\n",
      "        'annotations': \n",
      "          4454/4454x {\n",
      "            'XXX': \n",
      "              12577/12577x [\n",
      "                  23222/23222x {\n",
      "                    'valid_reasoning': 23222/23222x number\n",
      "                    'evidence_start': 23222/23222x [24249/24249x number]\n",
      "                    'label_code': 23222/23222x number\n",
      "                    'prompt_id': 23222/23222x non-empty string\n",
      "                    'evidence_end': 23222/23222x [24249/24249x number]\n",
      "                    'valid_label': 23222/23222x number\n",
      "                    'label': 23222/23222x non-empty string\n",
      "                    'pmc_id': 23222/23222x non-empty string\n",
      "                    'annotations': \n",
      "                      23222/23222x [\n",
      "(1): 24242/24249x non-empty string || (2): 7/24249x empty string\n",
      "                      ]\n",
      "                    'in_abstract': 23222/23222x [24249/24249x number]\n",
      "                    'evidence_text': \n",
      "                      23222/23222x [\n",
      "(1): 23305/24249x non-empty string || (2): 944/24249x empty string\n",
      "                      ]\n",
      "                    'user_id': 23222/23222x non-empty string\n",
      "                  }\n",
      "              ]\n",
      "          }\n",
      "        'ix_counter': 4454/4454x number\n",
      "        'prompts': \n",
      "          4454/4454x {\n",
      "            'XXX': \n",
      "              12730/12730x {\n",
      "                'comparator': 12730/12730x non-empty string\n",
      "                'prompt_id': 12730/12730x non-empty string\n",
      "                'intervention': 12730/12730x non-empty string\n",
      "                'pmc_id': 12730/12730x non-empty string\n",
      "                'outcome': 12730/12730x non-empty string\n",
      "              }\n",
      "          }\n",
      "      }\n",
      "  ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import metadata_analyzer\n",
    "\n",
    "\n",
    "def _value_to_pattern(value, point):\n",
    "    if isinstance(value, dict):\n",
    "        if point.key in [\"prompts\", \"annotations\"]:\n",
    "            return metadata_analyzer._Pattern(kind=metadata_analyzer._PatternKind.OBJECT, keys={\"XXX\"}, point=point,\n",
    "                                              data=[value])\n",
    "        else:\n",
    "            return metadata_analyzer._Pattern(kind=metadata_analyzer._PatternKind.OBJECT, keys=set(value.keys()),\n",
    "                                              point=point, data=[value])\n",
    "    if isinstance(value, list):\n",
    "        return metadata_analyzer._Pattern(kind=metadata_analyzer._PatternKind.ARRAY, keys=[], point=point, data=[value])\n",
    "    if isinstance(value, str):\n",
    "        if metadata_analyzer._DIFF_EMPTY_STRING:\n",
    "            return metadata_analyzer._Pattern(kind=metadata_analyzer._PatternKind.STRING,\n",
    "                                              keys=[\"empty\" if value == \"\" else \"non-empty\"], point=point,\n",
    "                                              data=[value])\n",
    "        else:\n",
    "            return metadata_analyzer._Pattern(kind=metadata_analyzer._PatternKind.STRING, keys=[], point=point,\n",
    "                                              data=[value])\n",
    "    if isinstance(value, int) or isinstance(value, float):\n",
    "        return metadata_analyzer._Pattern(kind=metadata_analyzer._PatternKind.NUMBER, keys=[], point=point,\n",
    "                                          data=[value])\n",
    "    if isinstance(value, bool):\n",
    "        if metadata_analyzer._DIFF_TRUE_FALSE:\n",
    "            return metadata_analyzer._Pattern(kind=metadata_analyzer._PatternKind.STRING,\n",
    "                                              keys=[\"true\" if value else \"false\"], point=point, data=[value])\n",
    "        else:\n",
    "            return metadata_analyzer._Pattern(kind=metadata_analyzer._PatternKind.BOOL, keys=[], point=point,\n",
    "                                              data=[value])\n",
    "    if value is None:\n",
    "        return metadata_analyzer._Pattern(kind=metadata_analyzer._PatternKind.NULL, keys=[], point=point, data=[value])\n",
    "\n",
    "    raise ValueError(f\"Unknown JSON value! {type(value)}\")\n",
    "\n",
    "\n",
    "metadata_analyzer._value_to_pattern = _value_to_pattern\n",
    "\n",
    "\n",
    "def _process_point(point):\n",
    "    # cluster the values into patterns\n",
    "    for value in point.data:\n",
    "        new_pattern = metadata_analyzer._value_to_pattern(value, point)\n",
    "        for pattern in point.patterns:\n",
    "            if pattern == new_pattern:\n",
    "                pattern.count += 1\n",
    "                pattern.data.append(value)\n",
    "                break\n",
    "        else:\n",
    "            point.patterns.append(new_pattern)\n",
    "\n",
    "    # go deeper into objects and arrays\n",
    "    for pattern in point.patterns:\n",
    "        if pattern.kind == metadata_analyzer._PatternKind.ARRAY:\n",
    "            data = [v for data in pattern.data for v in data]\n",
    "            child_point = metadata_analyzer._Point(parent=point, key=None, data=data)\n",
    "            pattern.children.append(child_point)\n",
    "            _process_point(child_point)\n",
    "        elif pattern.kind == metadata_analyzer._PatternKind.OBJECT:\n",
    "            if pattern.keys == {\"XXX\"}:\n",
    "                data = [v for data in pattern.data for v in data.values()]\n",
    "                child_point = metadata_analyzer._Point(parent=point, key=\"XXX\", data=data)\n",
    "                pattern.children.append(child_point)\n",
    "                _process_point(child_point)\n",
    "            else:\n",
    "                for key in pattern.keys:\n",
    "                    data = [v for data in pattern.data for k, v in data.items() if k == key]\n",
    "                    child_point = metadata_analyzer._Point(parent=point, key=key, data=data)\n",
    "                    pattern.children.append(child_point)\n",
    "                    _process_point(child_point)\n",
    "\n",
    "\n",
    "metadata_analyzer._process_point = _process_point\n",
    "\n",
    "metadata = [document.meta for document in documents]\n",
    "print(parse_json_object(metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Node Metadata Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/1x [\n",
      "      316870/316870x {\n",
      "        'is_evidence_for': \n",
      "          316870/316870x [\n",
      "              23943/23943x {\n",
      "                'prompt_id': 23943/23943x non-empty string\n",
      "                'evidence_ix': 23943/23943x number\n",
      "                'user_id': 23943/23943x non-empty string\n",
      "              }\n",
      "          ]\n",
      "      }\n",
      "  ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = [node.meta for document in documents for node in document.nodes]\n",
    "print(parse_json_object(metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prompts and Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num invalid label: 0\n",
      "num invalid reasoning 0\n"
     ]
    }
   ],
   "source": [
    "# assert validity of all annotations\n",
    "num_invalid_label = 0\n",
    "num_invalid_reasoning = 0\n",
    "for document in documents:\n",
    "    for annotations in document.meta[\"annotations\"].values():\n",
    "        for annotation in annotations:\n",
    "            if not annotation[\"valid_label\"]:\n",
    "                num_invalid_label += 1\n",
    "            if not annotation[\"valid_reasoning\"]:\n",
    "                num_invalid_reasoning += 1\n",
    "print(\"num invalid label:\", num_invalid_label)\n",
    "print(\"num invalid reasoning\", num_invalid_reasoning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Number of prompts per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of prompts: 12730\n"
     ]
    },
    {
     "data": {
      "text/plain": "    # prompts  # documents with this many prompts\n0           0                                1118\n6           1                                 353\n3           2                                 589\n2           3                                 608\n4           4                                 587\n1           5                                 647\n5           6                                 421\n7           7                                  70\n8           8                                  16\n9           9                                  15\n15         10                                   3\n11         11                                   4\n10         12                                   6\n13         13                                   4\n12         14                                   4\n14         15                                   3\n16         17                                   2\n18         20                                   1\n19         34                                   1\n17         55                                   1\n20         71                                   1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># prompts</th>\n      <th># documents with this many prompts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1118</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>353</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>589</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>608</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>587</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>647</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>421</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>34</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>55</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>71</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_prompts = collections.Counter()\n",
    "for document in documents:\n",
    "    num_prompts[len(document.meta[\"prompts\"])] += 1\n",
    "\n",
    "print(\"Total number of prompts:\", sum(x * y for x, y in num_prompts.items()))\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"# prompts\": [x for x, _ in num_prompts.most_common()],\n",
    "    \"# documents with this many prompts\": [x for _, x in num_prompts.most_common()]\n",
    "}).sort_values(\"# prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number of annotations per prompt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of annotations: 23030\n"
     ]
    },
    {
     "data": {
      "text/plain": "    # annotations  # prompts with this many annotations\n0               0                                  1118\n6               1                                   353\n3               2                                   589\n2               3                                   608\n4               4                                   587\n1               5                                   647\n5               6                                   421\n7               7                                    70\n8               8                                    16\n9               9                                    15\n15             10                                     3\n11             11                                     4\n10             12                                     6\n13             13                                     4\n12             14                                     4\n14             15                                     3\n16             17                                     2\n18             20                                     1\n19             34                                     1\n17             55                                     1\n20             71                                     1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># annotations</th>\n      <th># prompts with this many annotations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1118</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>353</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>589</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>608</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>587</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>647</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>421</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>34</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>55</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>71</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_annotations = collections.Counter()\n",
    "for document in documents:\n",
    "    for prompt_id in document.meta[\"prompts\"].keys():\n",
    "        if prompt_id not in document.meta[\"annotations\"].keys():\n",
    "            num_annotations[0] += 1\n",
    "        else:\n",
    "            annotations = document.meta[\"annotations\"][prompt_id]\n",
    "            num_annotations[len(annotations)] += 1\n",
    "\n",
    "print(\"Total number of annotations:\", sum(x * y for x, y in num_annotations.items()))\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"# annotations\": [x for x, _ in num_prompts.most_common()],\n",
    "    \"# prompts with this many annotations\": [x for _, x in num_prompts.most_common()]\n",
    "}).sort_values(\"# annotations\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Number of annotations per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of annotations: 23222\n"
     ]
    },
    {
     "data": {
      "text/plain": "    # annotations  # documents with this many annotations\n0               0                                    1118\n6               1                                     353\n3               2                                     589\n2               3                                     608\n4               4                                     587\n1               5                                     647\n5               6                                     421\n7               7                                      70\n8               8                                      16\n9               9                                      15\n15             10                                       3\n11             11                                       4\n10             12                                       6\n13             13                                       4\n12             14                                       4\n14             15                                       3\n16             17                                       2\n18             20                                       1\n19             34                                       1\n17             55                                       1\n20             71                                       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># annotations</th>\n      <th># documents with this many annotations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1118</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>353</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>589</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>608</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>587</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>647</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>421</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>34</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>55</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>71</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_annotations = collections.Counter()\n",
    "for document in documents:\n",
    "    num_annotations[sum(len(annotations) for annotations in document.meta[\"annotations\"].values())] += 1\n",
    "\n",
    "print(\"Total number of annotations:\", sum(x * y for x, y in num_annotations.items()))\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"# annotations\": [x for x, _ in num_prompts.most_common()],\n",
    "    \"# documents with this many annotations\": [x for _, x in num_prompts.most_common()]\n",
    "}).sort_values(\"# annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference Label Distribution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"no significant difference\": 10530,\n",
      "    \"significantly increased\": 7141,\n",
      "    \"significantly decreased\": 5551\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "num_labels = collections.Counter()\n",
    "for document in documents:\n",
    "    for prompt_id, annotations in document.meta[\"annotations\"].items():\n",
    "        for annotation in annotations:\n",
    "            num_labels[annotation[\"label\"]] += 1\n",
    "\n",
    "print(json.dumps(dict(num_labels), indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number of evidence nodes per annotation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "       num\n0-0    979\n1-1  21007\n2-2   1056\n3-3    118\n4-4     34\n≥5      28",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0-0</th>\n      <td>979</td>\n    </tr>\n    <tr>\n      <th>1-1</th>\n      <td>21007</td>\n    </tr>\n    <tr>\n      <th>2-2</th>\n      <td>1056</td>\n    </tr>\n    <tr>\n      <th>3-3</th>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>4-4</th>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>≥5</th>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_nodes = collections.Counter()\n",
    "for document in documents:\n",
    "    for prompt_id, annotations in document.meta[\"annotations\"].items():\n",
    "        for annotation in annotations:\n",
    "            user_id = annotation[\"user_id\"]\n",
    "            assert (prompt_id, user_id) not in evidence_nodes.keys()\n",
    "            evidence_nodes[(prompt_id, user_id)] = 0\n",
    "    for node in document.nodes:\n",
    "        for is_evidence_for in node.meta[\"is_evidence_for\"]:\n",
    "            evidence_nodes[(is_evidence_for[\"prompt_id\"], is_evidence_for[\"user_id\"])] += 1\n",
    "\n",
    "num_evidence_nodes = collections.Counter(evidence_nodes.values())\n",
    "\n",
    "histogram(num_evidence_nodes, 5, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Number of evidence spans per annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   # evidence spans  # answers with this many evidence spans\n0                 1                                    22457\n1                 2                                      591\n2                 3                                      125\n3                 4                                       30\n4                 5                                       11\n5                 6                                        4\n9                 7                                        1\n6                 8                                        1\n7                 9                                        1\n8                12                                        1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># evidence spans</th>\n      <th># answers with this many evidence spans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>22457</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>591</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>125</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_evidence = collections.Counter()\n",
    "for document in documents:\n",
    "    for annotations in document.meta[\"annotations\"].values():\n",
    "        for annotation in annotations:\n",
    "            num_evidence[len(annotation[\"evidence_text\"])] += 1\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"# evidence spans\": [count for count, _ in num_evidence.most_common()],\n",
    "    \"# answers with this many evidence spans\": [count for _, count in num_evidence.most_common()]\n",
    "}).sort_values(\"# evidence spans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Number of evidence nodes per evidence span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    # evidence nodes  # evidence spans with this many evidence nodes\n1                  0                                            1237\n0                  1                                           22313\n2                  2                                             649\n3                  3                                              35\n4                  4                                               3\n5                  5                                               2\n11                 6                                               1\n8                  8                                               1\n9                  9                                               1\n12                11                                               1\n14                20                                               1\n6                 23                                               1\n7                 26                                               1\n13                30                                               1\n15                31                                               1\n10                41                                               1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># evidence nodes</th>\n      <th># evidence spans with this many evidence nodes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1237</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>22313</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>649</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>23</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>26</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>30</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>31</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>41</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = collections.Counter()\n",
    "missed_evidence_spans = collections.Counter()\n",
    "for document in documents:\n",
    "    for prompt_id, annotations in document.meta[\"annotations\"].items():\n",
    "        for annotation in annotations:\n",
    "            counter = collections.Counter()\n",
    "            for node in document.nodes:\n",
    "                for is_evidence_for in node.meta[\"is_evidence_for\"]:\n",
    "                    if is_evidence_for[\"prompt_id\"] == prompt_id and is_evidence_for[\"user_id\"] == annotation[\"user_id\"]:\n",
    "                        counter[is_evidence_for[\"evidence_ix\"]] += 1\n",
    "            for ix in range(len(annotation[\"evidence_text\"])):\n",
    "                if counter[ix] == 0:\n",
    "                    missed_evidence_spans[annotation[\"evidence_text\"][ix]] += 1\n",
    "                num_nodes[counter[ix]] += 1\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"# evidence nodes\": [count for count, _ in num_nodes.most_common()],\n",
    "    \"# evidence spans with this many evidence nodes\": [count for _, count in num_nodes.most_common()]\n",
    "}).sort_values(\"# evidence nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Most often-occurring missing evidence spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    count                              missing evidence text\n0     944                                                   \n1       3  The control group obtained means that were 24%...\n2       3  s-controlled diabetes (above median baseline A...\n3       2  Pi‐AUC\\nmg*h/L\\n0.68a [–0.68‐3.5]\\n54.17b [37....\n4       2  Improved acceptance of illness\\n3.15 ± 0.51\\n3...\n5       2  Improved social well being\\n2.69 ± 0.90\\n3.46 ...\n6       2  Early apoptotic cells (annexin positive, PI ne...\n7       2  Infant hospital\\n Baseline\\n1.17 (3.26)\\n12/41...\n8       2  Number of fallers with injuries due to falls\\n...\n9       2  Pain index\\n-3.31 (0.68)\\n-4.90 (0.53)\\n-5.65 ...\n10      2  Total WEL score\\n-1.77 (1.45)\\n0.45 (1.19)\\n8....\n11      2  Major haemorrhage\\n33/2212 (1.5%)\\n57/2235 (2....\n12      2    Overall\\n12.6\\n13.6\\n0.137\\n11.6\\n12.7\\n0.08\\n*\n13      2  The mean number of topics discussed did not di...\n14      2  The mean number of daily boluses increased in ...\n15      2  Plasma Inflammatory cytokines\\n\\n\\n\\n\\n C-reac...\n16      2  Duration RRT prescribed, hrs\\n146 ± 240\\n145 ±...\n17      2  Duration RRT received, hrs\\n130 ± 222\\n128 ± 1...\n18      2  Mean RRT dose, mL/kg/hr\\n33.6 ± 7.4\\n34.7 ± 4....\n19      2  Prescribed dose delivered, %\\n84.7 ± 16.3\\n87....",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>missing evidence text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>944</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>The control group obtained means that were 24%...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>s-controlled diabetes (above median baseline A...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Pi‐AUC\\nmg*h/L\\n0.68a [–0.68‐3.5]\\n54.17b [37....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Improved acceptance of illness\\n3.15 ± 0.51\\n3...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>Improved social well being\\n2.69 ± 0.90\\n3.46 ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>Early apoptotic cells (annexin positive, PI ne...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>Infant hospital\\n Baseline\\n1.17 (3.26)\\n12/41...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>Number of fallers with injuries due to falls\\n...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>Pain index\\n-3.31 (0.68)\\n-4.90 (0.53)\\n-5.65 ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2</td>\n      <td>Total WEL score\\n-1.77 (1.45)\\n0.45 (1.19)\\n8....</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2</td>\n      <td>Major haemorrhage\\n33/2212 (1.5%)\\n57/2235 (2....</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2</td>\n      <td>Overall\\n12.6\\n13.6\\n0.137\\n11.6\\n12.7\\n0.08\\n*</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2</td>\n      <td>The mean number of topics discussed did not di...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2</td>\n      <td>The mean number of daily boluses increased in ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2</td>\n      <td>Plasma Inflammatory cytokines\\n\\n\\n\\n\\n C-reac...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>Duration RRT prescribed, hrs\\n146 ± 240\\n145 ±...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>Duration RRT received, hrs\\n130 ± 222\\n128 ± 1...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>Mean RRT dose, mL/kg/hr\\n33.6 ± 7.4\\n34.7 ± 4....</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>Prescribed dose delivered, %\\n84.7 ± 16.3\\n87....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"count\": [count for _, count in missed_evidence_spans.most_common(20)],\n",
    "        \"missing evidence text\": [text for text, _ in missed_evidence_spans.most_common(20)],\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}